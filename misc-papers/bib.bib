% vim: lbr et sw=4 sts=4
\usepackage{url}
@book{bayesianphysics2003,
    author = "Giulio D'Agostini",
    title = "Bayesian Reasoning in High Energy Physics: Principles and Applications",
    publisher = "World Scientific Publishing",
    year = "2003",
    address = "Singapore",
    annote = "Also available on the web at \verb!http://www-zeus.roma1.infn.it/~agostini/cern/cern.html!",
}
@inbook{ nwald-taking,
    author = "Peter Gr{{\"u}}nwald",
    chapter = "Taking the Sting out of Subjective Probability",
    title = "Words, Proofs, and Diagrams",
    editor = "D. Barker-Plummer and D. Beaver and J. van Benthem and P. Scotto Di Luzio",
    publisher = "CSLI Publications",
    address = "Stanford, CA",
    month = "June",
    year = "2002",
    annote = "Also available on the web at \verb!http://citeseer.nj.nec.com/454156.html!"
}
@inproceedings{moody-fastmulti,
    author = "John Moody",
    title = "Fast learning in multi-resolution hierarchies",
    editor = "D. S. Touretzky",
    booktitle = "Advances in neural information processing systems",
    pages = "29--39",
    publisher = "Morgan Kaufmann Publishers",
    address = "Carnegie Mellon University",
    year = "1989",
}
@article{chiang-gcmac,
    author = "Ching--Tsan Chiang and Chun--Shin Lin",
    title = "{CMAC} with general basis functions",
    journal = "Neural Networks",
    volume = "9",
    number = "7",
    pages = "1199--1211",
    year = "1996",
    publisher = "Elsevier Science, Ltd.",
    address = "Great Britain",
}
@article{albus-cmac,
    author = "J. S. Albus",
    title = "A New approach to manipulator control: The Cerebellar Model Articulation Controller ({CMAC})",
    journal = "Journal of Dynamic Systems, Measurement, and Control",
    volume = "97",
    number = "3",
    pages = "220--227",
    year = "1975",
    month = "September",
}
@article{albus-cmac-impl,
    author = "J. S. Albus",
    title = "Data Storage in the Cerebellar Model Articulation Controller ({CMAC})",
    journal = "Journal of Dynamic Systems, Measurement, and Control",
    volume = "97",
    number = "3",
    pages = "228--233",
    year = "1975",
    month = "September",
}
@article{lane-hocmac,
    author = "Stephen H. Lane and David A. Handelman and Jack J. Gelfand",
    title = "Theory and Development of Higher-Order {CMAC} Neural Networks",
    journal = "Control Systems Magazine",
    publisher = "IEEE",
    volume = "12",
    number = "2",
    month = "April",
    year = "1992",
}
@misc{wang-cacmac,
    author = "Yeng--ping Wang",
    title = "Credit Assigned Cerebella [sic] Model Articulation Controller",
    howpublished = "http://neuron.et.ntust.edu.tw/homework/89/NN/89homework\%232/M8907213/",
}
@mastersthesis{richardsthesis2003,
    author = "Mark Richards",
    title = "Improving Particle Swarm Optimization",
    school = "Brigham Young University Computer Science Department",
    year = "2003",
    annote = "Work on particle initialization (using centroidal voronoi approximations) and dynamic sociometries",
}
@inproceedings{richards2003,
    author = "Mark Richards and Dan Ventura",
    title = "Dynamic Sociometry in Particle Swarm Optimization",
    booktitle = "International Conference on Computational Intelligence and Natural Computing",
    year = "2003",
    month = "September",
    annote = "Explores dynamic sociometries and their effects on the convergence properties of a particle swarm.  Exceptional results shown on only one function in one circumstance.",
}
@inproceedings{kennedy1995,
    author = "James Kennedy and Russell C. Eberhart",
    title = "Particle Swarm Optimization",
    booktitle = "International Conference on Neural Networks IV",
    year=1995,
    address = "Piscataway, NJ",
    pages = "1942--1948",
    publisher = "IEEE Service Center",
    annote = "The seminal work on Particle Swarm Optimization, introducing the algorithm and the process through which it was discovered.",
}
@article{clerc2002kennedy,
    author = "Maurice Clerc and James Kennedy",
    title = "The Particle Swarm: Explosion, Stability, and Convergence in a Multidimensional Complex Space",
    journal = "{IEEE} Transactions on Evolutionary Computation",
    volume = "6",
    number = "1",
    month = "February",
    year = "2002",
    pages = "58--73",
    annote = "The behavior of particle swarms is studied in a simplified one-dimensional model without noise, giving rise to an enhanced understanding of convergence.  The mathematical study induces the notion of a constriction coefficient, which serves to keep velocities stable and to ensure convergence of the swarm over time.",
}
@inbook{sibson1981,
    author="Robin Sibson",
    chapter="A Brief Description of Natural Neighbor Interpolation",
    title ="Interpreting Multivariate Data",
    editor="V. Barnett",
    pages="236",
    publisher="John Wiley",
    year="1981",
}
@article{kalman1960,
    Author = {Rudolph Emil Kalman},
    Title = {A New Approach to Linear Filtering and Prediction Problems},
    Journal = {Transactions of the ASME--Journal of Basic Engineering},
    Volume = {82},
    Number = {Series D},
    Pages = {35-45},
    Year = {1960}
}
@article{kdtree,
    author="Volker Gaede and Oliver G{{\"u}}nther",
    title="Multidimensional Access Methods",
    journal="ACM Computing Surveys",
    volume=30,
    number=2,
    pages="170--231",
    month="June",
    year="1998"
}
@inproceedings{kennedymendes2002,
    author="James Kennedy and Rui Mendes",
    title="Population Structure and Particle Swarm Performance",
    booktitle="Proceedings of the Congress on Evolutionary Computation (CEC 2002)",
    address="Honolulu, Hawaii",
    year="2002",
}
@inproceedings{kennedy2003,
    author="James Kennedy",
    title="Bare Bones Particle Swarms",
    booktitle="Proceedings of the IEEE Swarm Intelligence Symposium 2003 (SIS 2003)",
    address="Indianapolis, Indiana",
    pages="80--87",
    year="2003",
    annote="The Bare Bones Particle Swarm was created after observing the statistical behavior of a particle executing the classical update formulas with fixed attractors.  It was discovered that the position of a particle in this situations takes on a Gaussian density over time, giving rise to the idea of compressing the whole PSO motion characteristics into a sample from a Gaussian distribution.  The basic idea of Bare Bones is encapsulated in a simple equations involving sampling from a Gaussian distribution.  This approach is probably the simplest invented and is surprisingly effective.  It captures many of the essential characteristics of PSO while simplifying it a great deal.",
}
@inproceedings{mendeskennedy2003,
    author="Rui Mendes and James Kennedy and J. Neves",
    title="Watch Thy Neighbor or How the Swarm Can Learn From its Environment",
    booktitle="Proceedings of the IEEE Swarm Intelligence Symposium 2003 (SIS 2003)",
    address="Indianapolis, Indiana",
    pages="88--94",
    year="2003",
    annote="Explores various topologies and also introduces the Schaffer F6 function, which I should implement.  Additionally, works with weighted neighborhoods instead of simple selection.",
}
@inproceedings{kennedymendes2003,
    author="James Kennedy and Rui Mendes",
    title="Neighborhood Topologies in Fully-Informed and Best-Of-Neighborhood Particle Swarms",
    booktitle="Proceedings of the 2003 IEEE SMC Workshop on Soft Computing in Industrial Applications (SMCia03)",
    year="2003", 
    address="Binghamton, New York",
    month="June",
    publisher="IEEE Computer Society",
    annote = "Fully-informed particle swarms do not differentiate between members of a neighborhood based on the best fitness achieved.  Instead, each particle combines information from all particles in its neighborhood when deciding where to go next.  This is interesting because it removes the need to make decisions about what information to use in the swarm process: use it all.  Amazingly enough, weighting the information from all of the particles randomly is quite effective.",
}
@inproceedings{kennedy1997,
    author="James Kennedy",
    title="The Particle Swarm: Social Adapatation of Knowledge",
    booktitle="Proceedings of the IEEE International Conference on Evolutionary Computation",
    address="Indianapolis, Indiana",
    pages="303--308",
    year="1997",
}
@inproceedings{kennedyeberhart1997,
    author="James Kennedy and R. C. Eberhart",
    title="A Discrete Binary Version of the Particle Swarm Algorithm",
    booktitle="Proceedings of the World Multiconference on Systemics, Cybernetics, and Informatics",
    address="Piscataway, New Jersey",
    pages="4104--4109",
    year="1997",
}
@inproceedings{kennedyspears1998,
    author="James Kennedy and W. Spears",
    title="Matching Algorithms to Problems: An Experimental Test of the Particle Swarm and Some Genetic Algorithms on the Multimodal Problem Generator",
    booktitle="Proceedings of the IEEE Congress on Evolutionary Computation (CEC 1998)",
    address="Anchorage, Alaska",
    year="1998",
}
@inproceedings{kennedy1999,
    author="James Kennedy",
    title="Small Worlds and Mega-Minds: Effects of Neighborhood Topology on Particle Swarm Performance",
    booktitle="Proceedings of the Congress of Evolutionary Computation",
    volume="3",
    publisher="IEEE Press",
    year="1999",
    pages="1931--1938",
}
%    editor="P. J. Angeline and Z. Michalewicz and M. Schoenauer and X. Yao and Z. Zalzala",
@inproceedings{kennedy2000,
    author="James Kennedy",
    title="Stereotyping: Improving Particle Swarm Performance With Cluster Analysis",
    booktitle="Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2000)",
    address="San Diego, California",
    pages="1507--1512",
    year="2000",
}
@mastersthesis{lovbjerg2002,
    author="Morten L{{\o}}vbjerg",
    title="Improving particle swarm optimization by hybridization of stochastic search heuristics and self-organized criticality",
    school="Department of Computer Science, University of Aarhus",
    year="2002",
}
@inproceedings{vesterstroem2002,
    author="Jakob S. Vesterstr{{\o}}m and Jacques Riget and Thiemo Krink",
    title="Division of Labor in Particle Swarm Optimisation",
    booktitle="Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2002)",
    address="Honolulu, Hawaii",
    year="2002",
    annote="DoLPSO algorithm presented, along with some weights.  Also presents a division of labor model.  Seems to be interesting work.",
}
@techreport{riget2002,
    author="Jacques Riget and Jakob S. Vesterstr{{\o}}m",
    title="A Diversity-Guided Particle Swarm Optimizer --- The {ARPSO}",
    number="2002-02",
    year="2002",
    institution="Department of Computer Science, University of Aarhus",
    publisher="EVALife",
    annote = "A description of the ARPSO algorithm, an approach that keeps the particle swarm exploring even when convergence would normally occur.  The approach is shown to be effective in avoiding premature convergence.",
}
@inproceedings{shi1999,
    author="Y. Shi and R. C. Eberhart",
    title="Empirical study of particle swarm optimization",
    booktitle="Proceedings of the IEEE Congress on Evolutionary Computation (CEC 1999)",
    address="Piscataway, New Jersey",
    pages="1945--1950",
    year="1999",
}
@inproceedings{krink2002,
    author="Thiemo Krink and Jakob S. Vestertroem and Jacques Riget",
    title="Particle swarm optimisation with spatial particle extension",
    booktitle="Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2002)",
    address="Honolulu, Hawaii",
    year="2002",
}
@book{russellnorvig2003,
    author="Stuart Russel and Peter Norvig",
    title="Artificial Intelligence: A Modern Approach",
    edition="Second",
    publisher="Prentice Hall",
    year="2003",
    address="Englewood Cliffs, New Jersey",
}
@inproceedings{shi1998eberhart,
    author="Y. Shi and R. C. Eberhart",
    title="Parameter selection in particle swarm optimization",
    booktitle="Evolutionary Programming VII: Proceedings of the Seventh Annual Conference on Evolutionary Programming",
    address="New York",
    pages="591--600",
    year="1998",
}
@inproceedings{seppi2004,
    author="Kevin D. Seppi and Michael Jones and Peter Lamborn",
    title="Guided Model Checking with a Bayesian Meta-heuristic",
    booktitle="Proceedings of the Fourth International Conference on Application of Concurrency to System Design",
    address="Hamilton, Ontario, Canada",
    year="2004",
    pages="217--226",
}
@inproceedings{monson2004,
    author="Christopher K. Monson and Kevin D. Seppi",
    title="The {Kalman} Swarm",
    booktitle="Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO} 2004)",
    address="Seattle, Washington",
    pages="140--150",
    volume="1",
    year="2004",
    annote="Uses a Kalman Filter to predict the next best place to search for a minimum in PSO.",
}
@inproceedings{monson2004a,
    author="Christopher K. Monson and Kevin D. Seppi",
    title="Improving on the {Kalman} Swarm: Extracting Its Essential Characteristics",
    booktitle="Late Breaking Papers of the Genetic and Evolutionary Computation Conference ({GECCO} 2004)",
    address="Seattle, Washington",
    year="2004",
    annote = "Simplifies the Kalman Filter PSO, producing an algorithm that is easier to tune and that works better on benchmark tests.",
}
@inproceedings{monson2004b,
    author="Christopher K. Monson and David Wingate and Kevin D. Seppi and Todd S. Peterson",
    title="Variable Resolution Discretization in the Joint Space",
    booktitle="Proceedings of the International Conference on Machine Learning and Applications",
    address="Louisville, Kentucky",
    pages="449--455",
    year="2004",
}
@inproceedings{monson2005a,
    author="Christopher K. Monson and Kevin D. Seppi",
    title="Bayesian Optimization Models for Particle Swarms",
    booktitle="Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO} 2005)",
    address="Washington, D.C.",
    pages="193--200",
    volume="1",
    year="2005",
    annote = "A Hidden Markov Model (HMM) is introduced which models the process of swarm optimization.  A result of this model is the Kalman Swarm, which can be simplified to appear the same as many classical PSO variants.  The model is used to explain why and under what circumstances PSO is effective as well as to suggest ways in which parameters may be tuned.",
}
@inproceedings{monson2005b,
    author="Christopher K. Monson and Kevin D. Seppi",
    title="Exposing Origin-Seeking Bias in PSO",
    booktitle="Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO} 2005)",
    address="Washington, D.C.",
    pages="241--248",
    volume="1",
    year="2005",
}
@inproceedings{monson2005c,
    author="Christopher K. Monson and Kevin D. Seppi",
    title="Linear Equality Constraints and Homomorphous Mappings in PSO",
    booktitle="Proceedings of the Congress on Evolutionary Computation",
    address="Edinburgh, U.K.",
    pages="73--80",
    volume="1",
    year="2005",
}
@inproceedings{wingate2004a,
    author="David Wingated and Kevin D. Seppi",
    title="P3VI: A Partitioned, Prioritized, Parallel Value Iterator",
    booktitle="Proceedings of the International Conference on Machine Learning",
    year="2004",
    address="Banff, Canada",
}
@inproceedings{wingate2004b,
    author="David Wingated and Kevin D. Seppi",
    title="Cache Performance of Priority Metrics for MDP Solvers",
    booktitle="Proceedings of the 2004 AAAI Workshop on Learning and Planning in Markov Processes",
    year="2004",
    address="San Jose, California",
}
@inproceedings{carroll2004,
    author="James L. Carroll and Kevin D. Seppi",
    title="A Bayesian Technique for Task Lacalization in Multiple Goal Markov Decision Processes",
    booktitle="Proceedings of the International Conference on Machine Learning and Applications",
    year="2004",
    address="Louisville, Kentucky",
}
@book{leondes1970,
    editor="Cornelius T. Leondes",
    title="Theory and Applications of {Kalman} Filtering",
    publisher="North Atlantic Treaty Organization, Advisory Group for Aerospace Research and Development",
    year="1970",
    series="{AGARDograph}",
    number="139",
}
@article{ wolpert97no,
    author = "David H. Wolpert and William G. Macready",
    title = "No Free Lunch Theorems for Optimization",
    journal = "IEEE Transactions on Evolutionary Computation",
    volume = "1",
    number = "1",
    month = "April",
    pages = "67-82",
    year = "1997",
    url = "citeseer.ist.psu.edu/wolpert96no.html",
    annote = "Proofs are presented that all optimization algorithms have the same performance as random search when their behavior is amortized over all possible functions.  While unsurprising on one level, this result has received a great deal of attention because of its implications.  Though the proof applies only to discrete function optimization, it is argued that application to continuous optimization is trivial in the real world, where finite computers perform simulations or data is gathered from sensors with limited resolution.",
}
@inproceedings{ angelinepso1998,
    author = "Peter J. Angeline",
    title = "Using Selection to Improve Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 1998)",
    year="1998",
    address="Anchorage, Alaska, USA",
    annote="A note on why it's good to do initialization spread out around the space, and using tournament selection to make the PSO perform better.",
}
@inproceedings{ shipso1998,
    author="Yuhui Shi and Russell C. Eberhart",
    title = "A Modified Particle Swarm Optimizer",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 1998)",
    year = "1998",
    address = "Piscataway, New Jersey",
    annote="This work introduces the concept of an inertia weight to PSO.  The inertia weight is a tunable parameter that has a significant impact on swarm performance, allowing the practitioner a way to specify how much exploration vs. exploitation should be done by the swarm.",
}
@inproceedings{ ozcanpso1999,
    author = "Ender Ozcan and Chilukuri K. Mohan",
    title = "Particle Swarm Optimizaton: Surfing the Waves",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 1999)",
    year = "1999",
    address = "Washington, D.C.",
    annote = "An analysis of convergence and other issues in PSO -- very mathematical",
}
@inproceedings{ suganthanpso1999,
    author = "P.N. Suganthan",
    title = "Particle Swarm Optimiser with Neighborhood Operator",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 1999)",
    year = "1999",
    address = "Piscataway, New Jersey",
    pages = "1958--1962",
}
@inproceedings{ carlislepso2000,
    author = "Anthony J. Carlisle and Gerry Dozier",
    title = "Adapting Particle Swarm Optimization to Dynamic Environments",
    booktitle = "Proceedings of the International Conference on Artificial Intelligence (ICAI 2000)",
    year = "2000",
    address = "Las Vegas, Nevada",
    pages = "429--434",
}
@inproceedings{ eberhartpso2000,
    author="Russell C. Eberhart and Yuhui Shi",
    title = "Comparing Inertia Weights and Constriction Factors in Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2000)",
    year = "2000",
    address = "San Diego, California",
    pages = "84--88",
}
@inproceedings{ clercpso1999,
    author="Maurice Clerc",
    title = "The Swarm and the Queen: Towards a Deterministic and Adaptive Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 1999)",
    year = "1999",
    address = "Piscataway, New Jersey",
    pages = "1951--1957",
    annote = "Introduces the idea of constriction coefficient, adding no-hope and re-hope strategies into the mix.  An ecclectic blend of ideas, to be sure."
}
@inproceedings{ kennedypso2000,
    author="James Kennedy",
    title = "Stereotyping: Improving Particle Swarm Performance with Cluster Analysis",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2000)",
    year = "2000",
    address = "San Diega, California",
    pages = "1507--1512",
}
@techreport{ carlislepsotechreport2001,
    author = "Anthony J. Carlisle and Gerry Dozier",
    title = "Tracking Changing Extrema with Particle Swarm Optimizer",
    number="CSSE01-08",
    year = "2001",
    institution="Auburn University",
}
@inproceedings{ carlislepso2001,
    author = "Anthony J. Carlisle and Gerry Dozier",
    title = "An Off-The-Shelf {PSO}",
    booktitle = "Proceedings of the Workshop on Particle Swarm Optimization",
    year = "2001",
    address = "Indianapolis, Indiana",
}
@inproceedings{ eberhartpsosummary2001,
    author = "Russell C. Eberhart and Yuhui Shi",
    title = "Particle Swarm Optimization: Developments, Applictions, and Resources",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2001)",
    year = "2001",
    address = "Seoul, Korea",
    annote = "A nice survey of advances in PSO until this point in time, especially focusing on vmax, inertia weight, and constriction coefficient, as well as using it for multiobjective problems."
}
@inproceedings{ hupsosummary2004,
    author = "Xiaohi Hu and Yuhui Shi and Russell C. Eberhart",
    title = "Recent Advances in Particle Swarm",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2004)",
    year = "2004",
    address = "Portland, Oregon",
    pages = "90--97",
}
@inproceedings{ eberhartpso2001,
    author = "Russell C. Eberhart and Yuhui Shi",
    title = "Tracking and Optimizing Dynamic Systems with Particle Swarms",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2001)",
    year = "2001",
    address = "Seoul, Korea",
}
@inproceedings{ lovbjergpso2001,
    author = "Morten L{{\o}}vbjerg and Thomas Kiel Rasmussen and Thiemo Krink",
    title = "Hybrid Particle Swarm Optimiser with Breeding and Subpopulations",
    booktitle = "Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO} 2001)",
    year = "2001",
}
@inproceedings{ parsopoulospso2001a,
    author="Konstantinos E. Parsopoulos and Vassilis P. Plagianakos and George D. Magoulas and Michael N. Vrahatis",
    title = "Improving Particle Swarm Optimizer by Function ``Stretching''",
    booktitle = "Advances in Convex Analysis and Global Optimization",
    year = "2001",
    pages = "445--457",
    annote = "Very cool technique to change the function's output and make things go downhill in more of a global way."
}
@inproceedings{ parsopoulospso2001b,
    author="Konstantinos E. Parsopoulos and Vassilis P. Plagianakos and George D. Magoulas and Michael N. Vrahatis",
    title = "Stretching Technique for Obtaining Global Minimizers Through Particle Swarm Optimization",
    booktitle = "Proceedings of the Workshop on Particle Swarm Optimization",
    year = "2001",
    address = "Indianapolis, Indiana",
    annote = "Very cool technique to change the function's output and make things go downhill in more of a global way."
}
@inproceedings{ raypso2001,
    author="Tapabrata Ray and K. M. Liew",
    title = "A Swarm with an Effective Information Sharing Mechanism for Unconstrained and Constrained Single Objective Optimization Problem",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2001)",
    address = "Seoul, Korea",
    pages = "75--80",
    year = "2001",
}
@inproceedings{ shipso2001,
    author="Yuhui Shi and Russell C. Eberhart",
    title = "Particle Swarm Optimization with Fuzzy Adaptive Inertia Weight",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2001)",
    address = "Seoul, Korea",
    year = "2001",
}
@inproceedings{ alkazemipso2002a,
    author="Buthainah Al-kazemi and Chilukuri K. Mohan",
    title = "Multi-Phase Generalization of the Particle Swarm Optimization Algorithm",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2002)",
    address = "Honolulu, Hawaii",
    year = 2002,
}
@inproceedings{ alkazemipso2002b,
    author="Buthainah Al-kazemi and Chilukuri K. Mohan",
    title = "Multi-Phase Discrete Particle Swarm Optimization",
    booktitle = "Proceedings of the Fourth International Workshop on Frontiers in Evolutionary Algorithms (FEA 2002)",
    year = 2002,
}
@inproceedings{ blackwellpso2002a,
    author = "Tim M. Blackwell and Peter J. Bentley",
    title = "Dynamic Search with Charged Swarms",
    booktitle = "Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO} 2002)",
    year = "2002",
    address = "New York, New York",
    pages = "19--26",
}
@inproceedings{ blackwellpso2002b,
    author = "Tim M. Blackwell and Peter J. Bentley",
    title = "Don't Push Me!  Collision-Avoiding Swarms",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2002)",
    address = "Honolulu, Hawaii",
    year = "2002",
}
@inproceedings{ britspso2002,
    author="Riaan Brits and Andries P. Engelbrecht and Frans van den Bergh",
    title = "A Niching Particle Swarm Optimizer",
    booktitle = "Proceedings of the 4th Asia-Pacific Conference on Simulated Evolution and Learning (SEAL 2002)",
    year = "2002",
    address = "Singapore",
    pages = "692--696",
}
@inproceedings{ carlislepso2002,
    author = "Anthony J. Carlisle and Gerry Dozier",
    title = "Tracking Changing Extrema with Adaptive Particle Swarm Optimizer",
    booktitle = "Proceedings of the 5th Biannual World Automation Congress",
    year = "2002",
    address = "Orlando, Florida",
    pages = "265--270",
}
@article{ coellopso2002a,
    author = "Carlos A. {Coello Coello} and Gregorio Toscano Pulido and Maximino Salazar Lechuga",
    title = "Handling Multiple Objectives with Particle Swarm Optimization",
    journal = "IEEE Transactions on Evolutionary Computation",
    volume = 8,
    number = 3,
    month = "June",
    year = "2004",
    pages = "256--279",
}
@inproceedings{ coellopso2002b,
    author = "Carlos A. {Coello Coello} and Maximino Salazar Lechuga",
    title = "{MOPSO}: A Proposal for Multiple Objective Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2002)",
    address = "Honolulu, Hawaii",
    year = "2002",
}
@article{ fanpso2002,
    author = "Huiyuan Fan",
    title = "A Modification to Particle Swarm Optimization Algorithm",
    journal = "Engineering Computations",
    volume = 19,
    number = "7--8",
    pages = "970--989",
    year = "2002",
}
@inproceedings{ krink2002a,
    author = "Thiemo Krink and Morten L{{\o}}vbjerg",
    title = "The Life Cycle Model: Combining Particle Swarm Optimisation, Genetic Algorithms, and Hill Climbers",
    booktitle = "Proceedings of Parallel Problem Solving from Nature VII (PPSN 2002)",
    pages = "621--630",
    year = "2002",
    publisher = "Lecture Notes in Computer Science (LNCS)",
}
@inproceedings{ lovbjergpso2002,
    author = "Morten L{{\o}}vbjerg and Thiemo Krink",
    title = "Extending Particle Swarm Optimisers with Self-Organized Criticality",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2002)",
    address = "Honolulu, Hawaii",
    year = "2002"
}
@article{ parsopoulospso2002,
    author="Konstantinos E. Parsopoulos and Michael N. Vrahatis",
    title = "Initializing the Particle Swarm Optimizer Using the Nonlinear Simplex Method",
    editor = "A. Grmela and N. E. Mastorakis",
    journal = "Advances in Intelligent Systems, Fuzzy Systems, Evolutionary Computation",
    publisher = "WSEAS Press",
    year = "2002",
    pages = "216--221",
}
@phdthesis{ vandenberghpso2002,
    author = "Frans van den Bergh",
    title = "An Analysis of Particle Swarm Optimizers",
    school = "University of Pretoria, South Africa",
    address = "Department of Computer Science",
    year = "2002",
}
@inproceedings{ vandenberghpso2002a,
    author = "Frans van den Bergh and Andries P. Engelbrecht",
    title = "A New Locally Convergent Particle Swarm Optimizer",
    booktitle = "Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics (SMC 2002)",
    year = "2002",
    pages = "96--101",
}
@inproceedings{ vesterstroempso2002,
    author = "Jakob S. Vesterstr{{\o}}m and Jacques Riget, and Thiemo Krink",
    title = "Division of Labor in Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2002)",
    address = "Honolulu, Hawaii",
    year = "2002",
}
@inproceedings{ britspso2003,
    author = "Riaan Brits and Andries P. Engelbrecht and Frans van den Bergh",
    title = "Scalability of Niche {PSO}",
    booktitle = "Proceedings of the IEEE Swarm Intelligence Symposium (SIS 2003)",
    address = "Indianapolis, Indiana",
    pages = "228--234",
    year = "2003",
}
@inproceedings{ coathpso2003,
    author = "Genevieve Coath and Saman K. Halgamuge",
    title = "A Comparison of Constraint-Handling Methods for the Application of Particle Swarm Optimization to Constrained Nonlinear Optimization Problems",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2003)",
    year = "2003",
    pages = "2419--2425",
}
@inproceedings{ higashipso2003,
    author = "Natsuki Higashi and Hitoshi Iba",
    title = "Particle Swarm Optimization with Gaussian Mutation",
    booktitle = "Proceedings of the IEEE Swarm Intelligence Symposium (SIS 2003)",
    address = "Indianapolis, Indiana",
    pages = "72--79",
    year = 2003,
}
@inproceedings{ jansonpso2003,
    author = "Stefan Janson and Martin Middendorf",
    title = "A Hierarchical Particle Swarm Optimizer",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2003)",
    year = "2003",
    address = "Canbella, Australia",
    pages = "770--776",
}
@inproceedings{ paquetpso2003a,
    author = "Ulrich Paquet and Andries P. Engelbrecht",
    title = "A New Particle Swarm Optimizer for Linearly Constrained Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2003)",
    year = "2003",
    address = "Canbella, Australia",
    pages = "227--233",
    annote = "A particle swarm algorithm that is suitable for search in linearly constrained spaces is introduced.  By restricting the classical PSO equations to scalar multipliers, particles can only fly within the linear constraints in which they are initialized.  This allows PSO to be applied to e.g. support vector machines.",
}
@inproceedings{ paquetpso2003b,
    author = "Ulrich Paquet and Andries P. Engelbrecht",
    title = "Training Support Vector Machines with Particle Swarms",
    booktitle = "Proceedings of the International Joint Conference on Neural Networks (IJCNN 2003)",
    year = "2003",
    pages = "1598--1603",
}
@inproceedings{ parsopoulospso2003,
    author="Konstantinos E. Parsopoulos and Michael N. Vrahatis",
    title = "Investigating the Existence of Function Roots Using Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2003)",
    year = "2003",
    address = "Canbella, Australia",
    pages = "1448--1455",
}
@inproceedings{ perampso2003,
    author = "Thanmaya Peram and Kalyan Veeramachaneni and Chilukuri K. Mohan",
    title = "Fitness-Distance-Ratio Based Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Swarm Intelligence Symposium (SIS 2003)",
    year = "2003",
    address = "Indianapolis, Indiana",
    pages = "174--181",
}
@inproceedings{ secrestpso2003,
    author = "Barry R. Secrest and Gary B. Lamont",
    title = "Visualizing Particle Swarm Optimization -- Gaussian Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Swarm Intelligence Symposium (SIS 2003)",
    year = "2003",
    address = "Indianapolis, Indiana",
    pages = "198--204",
}
@inproceedings{ tingpso2003,
    author = "Tiew-On Ting and M. V. C. Rao and C. K. Loo and Sze-San Ngu",
    title = "A New Class of Operators to Accelerate Particle Swarm Optimization",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2003)",
    year = "2003",
    address = "Canbella, Australia",
    pages = "2406--2410",
}
@inproceedings{ zhengpso2003,
    author = "{Yong-ling} Zheng and {Long-hua} Ma and {Li-yan} Zhang and {Ji-xin} Qian",
    title = "Empirical Study of Particle Swarm Optimizer with an Increasing Inertia Weight",
    booktitle = "Proceedings of the IEEE Congress on Evolutionary Computation (CEC 2003)",
    year = "2003",
    address = "Canbella, Australia",
    pages = "221--226",
}
@inproceedings{ clercpso2003,
    author = "Maurice Clerc",
    title = "{TRIBES} - Un exemple d'optimisation par essaim particulaire sans param{{\`e}}tres de contr{{\^o}}le",
    booktitle = "Optimisation par Essaim Particulaire (OEP 2003)",
    year = "2003",
    address = "Paris, France",
}
@misc{ perduebibliography,
    author = "Xiaohi Hu",
    title = "{PSO} Bibliography",
    howpublished = "Online at \url{http://www.swarmintelligence.org/}",
    year = "2004",
}
@misc{ clercwebsite,
    author = "Maurice Clerc",
    title = "Math Stuff About {PSO}",
    howpublished = "Online at \url{http://clerc.maurice.free.fr/pso/}",
    year = "2004",
}
@book{ swarmintelligence,
    author = "James Kennedy and Russell C. Eberhart",
    title = "Swarm Intelligence",
    publisher = "Morgan Kaufmann Publishers",
    year = "2001",
    annote = "Introduces the notion of social algorithms, discussing their power and applicability to optimization and other interesting problems.  Emergent intelligence is discussed at length.  Particle Swarm Optimization is positioned in the larger field of social behavior.",
}
@article{ mendespso2004,
    author = "Rui Mendes and James Kennedy and Jos{{\'e}} Neves",
    title = "The Fully Informed Particle Swarm: Simpler, Maybe Better",
    journal = "IEEE Transactions on Evolutionary Computation",
    month = "June",
    year = "2004",
    volume = "8",
    number = "3",
}
@article{ defreitas2000,
    author = "J. F. G. De Freitas and M. A. Niranjan and A. H. Gee and A. Doucet",
    title = "Sequential Monte Carlo Methods to Train Neural Network Models",
    journal = "Neural Computation",
    month = "April",
    year = "2000",
    volume = 12,
    number = 4,
    pages = "955--993",
    publisher = "MIT Press",
    annote = "The training of a neural network is accomplished by means of Bayesian inference.  The weights of the network are hidden, and the training examples are treated as resulting observations.  The distributions are not simply Gaussian and cannot be assumed to be easily parameterized, so particle filters are used to generate distribution estimates.  The network weights are assigned an evolution function which allows them to migrate over time and the likelihood of observing real data is assumed to be proportional to a Gaussian density function.  It is mentioned that this approach bears some similarity to existing evolutionary methods in that it uses a population of samples to do its work, and that population changes over time.",
}
@inbook{ liu00combined,
    author = "J. Liu and M. West",
    title = "Combined parameter and state estimation in simulation-based filtering",
    editor = "A. Doucet and J. F. G. De Freitas and N. J. Gordon", 
    booktitle = "Sequential Monte Carlo Methods in Practice. New York",
    publisher = "Springer-Verlag, New York",
    month = "January",
    year = "2001",
    url = "citeseer.ist.psu.edu/liu00combined.html",
    annote = "The notion of ``artificial evolution'' is explored and justified, showing that it is equivalent to using a kernel smoothing method on the distribution estimate in sample-based inference.  This is critical in learning parameters because parameters generally do not evolve like state.",
}
@techreport{ doucetsimulation1998,
    author = "A. Doucet",
    title = "On Sequential Simulation-based Methods for Bayesian Filtering",
    number = "CUED/F-INFENG/TR.310",
    year = "1998",
    institution = "Cambridge University",
}
@article{ pitt99filtering,
    author = "Michael K. Pitt and Neil Shephard",
    title = "Filtering via Simulation: Auxiliary Particle Filters",
    journal = "Journal of the American Statistical Association",
    volume = "94",
    number = "446",
    pages = "590--630",
    year = "1999",
    url = "citeseer.ist.psu.edu/pitt97filtering.html" }
}
@InProceedings{cuipso2004,
  title     = {A New Stochastic Particle Swarm Optimizer},
  author    = {Zhihua Cui and Jianchao Zeng and Xingjuan Cai},
  pages     = {316--319},
  booktitle = {Proceedings of the 2004 IEEE Congress on Evolutionary Computation},
  year      = {2004},
  publisher = {IEEE Press},
  month     = {20-23 June},
  address   = {Portland, Oregon},
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm \& differential evolution},
  abstract  = {
Particle Swarm Optimizer is a novel algorithm where a population of candidate
problem solution vectors evolves "social" norms by being influenced by their
topological neighbors.The standard Particle Swarm Optimizer may prematurely
converge on suboptimal solutions that are not even guaranteed to be local
extrema. A new particle swarm optimizer, called stochastic PSO, which is
combined with Tabu technique, is presented based on the analysis of the
standard PSO. And the global convergence analysis is made using the F.Solis
and R.Wets' research results.Finally, several examples are simulated to show
that SPSO is more efficient than the standard PSO.
},
  notes     = {CEC 2004 - A joint meeting of the IEEE, the EPS, and the IEE.},
}
@article{ pelikansurvey2002,
    title="A Survey of Optimization by Building and Using Probabilistic Models",
    author="Martin Pelikan and David E. Goldberg and Fernando Lobo",
    journal="Computational Optimization and Applications",
    publisher="Springer Science+Business Media B.V., Formerly Kluwer Academic Publishers B.V.",
    pages="5--20",
    volume="21",
    number="1",
    month="January",
    year="2002",
    annote="A short survey of various approaches to probabilistic model-building evolutionary algorithms is presented.  The idea itself is explored, then the field is split into several high-level approaches, each of which gets some attention.  The amount and type of interdepency which can be represented by a particular algorithm is used as the basis for classification.",
}
@inproceedings{ wunschmdp2004,
    title="Evolutionary algorithms, Markov decision processes, adaptive critic designs, and clustering: commonalities, hybridization and performance",
    author="Donald C. Wunsch, II and Samuel Mulder",
    booktitle="Proceedings of International Conference on Intelligent Sensing and Information Processing (ICISIP) 2004",
    year="2004",
    pages="477--482",
}
@inproceedings{ pelikan00research,
    author = "Martin Pelikan and David E. Goldberg",
    title = "Research on the Bayesian optimization algorithm",
    booktitle = "Optimization By Building and Using Probabilistic Models",
    month = "August",
    address = "Las Vegas, Nevada, USA",
    pages = "216--219",
    year = "2000",
    url = "citeseer.ist.psu.edu/pelikan00research.html"
}
@inproceedings{ pelikan00hierarchical,
    author = "Martin Pelikan and David E. Goldberg",
    title = "Hierarchical Problem Solving by the Bayesian Optimization Algorithm",
    booktitle = "Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO} 2000)",
    month = "10-12",
    publisher = "Morgan Kaufmann",
    address = "Las Vegas, Nevada, USA",
    editor = "Darrell Whitley and David Goldberg and Erick Cantu-Paz and Lee Spector and Ian Parmee and Hans-Georg Beyer",
    isbn = "1-55860-708-0",
    pages = "267--274",
    year = "2000",
    url = "citeseer.ist.psu.edu/pelikan00hierarchical.html"
}
@article{ baluja2002,
    author="Shumeet Baluja",
    title="Using A Priori Knowledge to Create Probabilistic Models for Optimization",
    journal="International Journal of Approximate Reasoning (IJAR)",
    volume="31",
    year="2003",
    number="3",
    pages="193--220",
    annote="In many cases, while creating a distribution based on a Bayesian network can capture complex interdependencies between variables, an inordinate number of samples may be required to generate a useful statistical model.  In order to reduce the number of samples required, it is often helpful to incorporate prior domain knowledge into the algorithm to direct its search for good representations.  This paper introduces the use of a priori limitation of Bayesian tree structure as a way of incorporating prior knowledge into the algorithm, especially when the optimization problem is structured in an amenable way.",
}
@techreport{Baluja_1994_1444,
   author = "Shumeet Baluja",
   title = "Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learning",
   institution = "Computer Science Department, Carnegie Mellon University",
   year = "1994",
   number = "CMU-CS-94-163",
   address = "Pittsburgh, PA",
   annote = "Introduces the PBIL method for learning a probability vector that is representative of the GA population at each time step.  Unlike the Bit-Based Simulated Crossover, this algorithm does not generate the probabilities from scratch at each time step, but adapts the vector over time as new information is gained from new populations.  In this sense, it learns the probabilities, hence the name.  The paper discusses at length the fact that population-based GAs are actually maintaining implicit statistics about the nature of the target function.  This approach is generally applicable to discrete problems.",
}
@inproceedings{ baluja1995,
    author="Shumeet Baluja and Rich Caruana",
    title="Removing the Genetics from the Standard Genetic Algorithm",
    booktitle="Proceedings of the International Conference on Machine Learning (ICML 1995)",
    year="1995",
    month="July",
    address="Lake Tahoe, California",
    pages="38--46",
    annote="The much shorter conference version of the ``Population-Based Incremental Learning'' paper.",
}
@incollection{ grefenstette93deception,
    author = "John J. Grefenstette",
    title = "Deception Considered Harmful",
    booktitle = "Foundations of Genetic Algorithms 2",
    publisher = "Morgan Kaufmann",
    address = "San Mateo, CA",
    editor = "L. Darrell Whitley",
    pages = "75--91",
    year = "1993",
    url = "citeseer.ist.psu.edu/grefenstette92deception.html"
}
@inproceedings{ kennedy2004,
    author = "James Kennedy",
    title = "Probability and Dynamics in the Particle Swarm",
    booktitle = "Proceedings of the Congress on Evolutionary Computation (CEC 2004)",
    month="June",
    year="2004",
    volume="1",
    pages="340--347",
    annote="Bare Bones Particle Swarms are surprisingly effective given their simplicity, but they do not capture all of the behavior of the classical PSO algorithm, nor do they perform as well.  The classical algorithm, when studied more carefully, can be seen to generate bursts of outliers from time to time that improve the swarm's exploration capabilities.  This paper presents an algorithm which, like Bare Bones, performs Gaussian sampling to move particles, but artificially adds bursts of outliers with some specified probability.  While this recaptured much of the statisticsal behavior of PSO, it did not appear to improve performance over Bare Bones significantly.",
}
@inproceedings{ kennedy2005,
    author = "James Kennedy",
    title = "Dynamic-Probabilistic Particle Swarms",
    booktitle = "Proceedings of the Genetic and Evolutionary Computation Conference (GECCO 2005)",
    month = "June",
    year = "2005",
    volume = "1",
    pages = "201--207",
    annote = "After failing to improve Bare Bones by adding bursts of outliers to the motion methodology, more study was done on the statistical properties of PSO.  Two new approaches were introduced, Truncated Uniform and Gaussian Dynamic Particle Swarms (TUPS and GDPS, respectively).  The former captures the statistics of PSO better than Bare Bones but does not significantly improve performance.  The latter makes observations about the math of PSO motion and uses the location to which a particle would normally go as a predictor from which a Gaussian sample is drawn to produce the final position.",
}
@techreport{ larranaga99optimization,
    author = "P. {{Larra\~naga}} and R. Etxeberria and J. A. Lozano and J. M. {{Pe\~na}}",
    title = "Optimization by Learning and Simulation of Bayesian and {Gaussian} Networks",
    number = "EHU-KZAA-IK-4/99",
    institution = "Department of Computer Science and Articial Intelligence, University of the Basque Country",
    year = "1999",
    url = "citeseer.ist.psu.edu/naga99optimization.html",
    annote = "This survey describes various approaches to estimating and using probability distributions in evolutionary computation.  Basic Estimation of Distribution Algorithms are explored, followed by those that do combinatorial optimization by using Bayesian networks, after which continuous domains and Gaussian networks are discussed.  The study of these areas suggests some algorithm improvments and extensions which are explored.",
}
@inproceedings{ syswerda1993,
    author = "Gilbert Syswerda",
    title = "Simulated Crossover in Genetic Algorithms",
    booktitle = "Proceedings of the Second Workshop on Foundations of Genetic Algorithms",
    address = "Vail, Colorado",
    publisher = "Morgan Kauffman",
    month = "July",
    year = "1993",
    pages = "239--255",
    isbn = "1-55860-263-1",
    annote="Introduces the Bit-Based Simulated Crossover (BSC) algorithm, which, rather than keep track of an explicit genetic population, collapses the information within the population into a probability vector.  Population statistics are calculated from scratch for each new population, then those statistics are used to generate a probability vector from which a new population is sampled.  This method assumes independence between all domain variables.",
}
@article{ debonet97mimic,
    author = "Jeremy S. de Bonet and Charles L. Isbell, Jr. and Paul Viola",
    title = "{MIMIC}: Finding Optima by Estimating Probability Densities",
    journal = "Advances in Neural Information Processing Systems",
    volume = "9",
    publisher = "The {MIT} Press",
    editor = "Michael C. Mozer and Michael I. Jordan and Thomas Petsche",
    pages = "424--431",
    year = "1997",
    url = "citeseer.ist.psu.edu/debonet96mimic.html",
    annote = "Presents an extension of PBIL which allows limited variable interdependencies to be statistically modeled using chains of conditional probabilities.  The chain is created using a greedy algorithm, which is known to be suboptimal because finding the optimal chain is an NP-complete problem.  Even so, it improves performance on functions where pairwise variable interdependencies exist.",
}
@InProceedings{Pelikan:99a,
    author = 	 "Martin Pelikan and David E. Goldberg and Erick Cant{\'{u}}-Paz",
    title = 	 "{BOA}: The {B}ayesian Optimization Algorithm",
    booktitle =    "Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO}-1999)",
    volume =       "I",
    pages =        "525--532",
    year =         "1999",
    editor =       "Wolfgang Banzhaf and Jason Daida and Agoston E. Eiben
        and Max H. Garzon and Vasant Honavar and Mark Jakiela
        and Robert E. Smith",
    ISBN =         "1-55860-611-4",
    address =      "Orlando, FL",
    publisher =    "Morgan Kaufmann Publishers, San Fransisco, CA",
    annote = "This work extends approaches like that found in {MIMIC} to incorporate general {Bayesian} models of probability distributions.  Once good members of a population have survived the selection process, the remaining population may be represented as a probability distribution encoded in a {Bayesian} network.  Such networks are interesting because they can encode a large class of distributions and it is easy to obtain samples from them.  This idea lends flexibility and power to the idea of using distributions to represent and generate populations and admits complex interdependencies between variables.",
}
@book{ holland1975,
    author = "John H. Holland",
    title = "Adaptation in Natural and Artificial Systems",
    publisher = "The University of Michigan Press",
    year = "1975",
    annote = "The definitive original work on genetic computation."
}
@book{ goldberg1989,
    author = "David E. Goldberg",
    title = "Genetic Algorithms in Search, Optimization, and Machine Learning",
    ISBN = "0-201-15767-5",
    publisher = "Addison-Wesley",
    year = "1989",
    month = "January",
}
@incollection{ whitleywatson2006,
    author = "Darrel Whitley and Jean Paul Watson",
    title = "Complexity Theory and the No Free Lunch Theorem",
    booktitle = "Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques",
    editor = "Edumnd K. Burke and Graham Kendall",
    publisher = "Springer",
    ISBN = "0-387-23460-8",
    year = "2006",
    annote = "This work is a tutorial on the connections between No Free Lunch (NFL) and algorithmic complexity theory.  It provides a gentle introduction to the ideas and ramifications of NFL while discussing relevant issues such as the futility of algorithmic comparison via empirical benchmark results, the fact that rank ordering of algorithms is, in fact, possible given many kinds of non-uniform distributions.  Many good references are provided for further research in the area."
}
@article{ igeltoussaint2004,
    author = "Christian Igel and Marc Toussaint",
    title = "A No-Free-Lunch Theorem for Non-Uniform Distributions of Target Functions",
    journal = "Journal of Mathematical Modelling and Algorithms",
    publisher = "Kluwer Academic Publishers",
    year = "2004",
    volume = "3",
    pages = "313--322",
    annote = "Establishes that No Free Lunch (NFL) does not hold when even very mild constraints are imposed on the probability of a particular function.  First, it is proven that a randomly selected subset of functions not at all likely to satisfy the closed-under-permutation requirement for NFL to hold.  Second, it shows that even if all possible functions are in the set, assigning them random probabilities is extremely likely to negate NFL (that is, to allow a rank ordering of algorithms over the chosen class).  These results, while not necessarily practically useful, demonstrate that NFL does not hold even under simple constraints.",
}
@inproceedings{ christensenoppacher2001,
    author = "Steffen Christensen and Franz Oppacher",
    title = "What Can We Learn From No Free Lunch?  A First Attempt to Characterize the Concept of a Searchable Function",
    booktitle = "Proceedings of the Genetic and Evolutionary Computation Conference ({GECCO} 2001)",
    year = "2001",
    pages = "1219--1226",
    publisher = "Morgan Kauffman",
    annote = "No Free Lunch has interesting implications for the optimization community, among which are the fact that any algorithm is bound to be ineffective when applied to any of a large class of functions.  This paper attempts to find ways of limiting the target function class that are meaningful and intuitive, and to prove that simple limitations on the class can allow a rank-ordering of optimization algorithms.  The example limitation chosen is self-similarity, which means that domain points close in space tend to produce range values that are also close.  Arguments of steepness are similar, and it is shown that this assumption of self-similarity sufficiently limits the class of interesting functions so that some algorithms outperform others.",
}
@article{ wolpert1996,
    author = "William G. Macready and David H. Wolpert",
    title = "What Makes an Optimization Problem Hard?",
    journal = "Complexity",
    volume = "5",
    year = "1996",
    annote = "The companion paper to the original work on No Free Lunch for optimization, this work.  This paper begins to address the difficult question of whether some optimization problems are actually harder than others, independent of the algorithm chosen to accomplish optimization.  The possible ties to Vapnik-Chervonenkis Dimension and Entropy are mentioned but not explored as ways of measuring the complexity of an optimization problem.",
}
@article{ aggarwal01surprising,
    author = "Charu C. Aggarwal and Alexander Hinneburg and Daniel A. Keim",
    title = "On the Surprising Behavior of Distance Metrics in High Dimensional Space",
    journal = "Lecture Notes in Computer Science",
    volume = "1973",
    pages = "420--434",
    year = "2001",
    url = "citeseer.ist.psu.edu/aggarwal01surprising.html"
}
@book{Bishop95,
    abstract = {This book provides a solid statistical foundation for neural networks from a pattern recognition perspective. The focus is on the types of neural nets that are most widely used in practical applications, such as the multi-layer perceptron and radial basis function networks. Rather than trying to cover many different types of neural networks, Bishop thoroughly covers topics such as density estimation, error functions, parameter optimization algorithms, data pre-processing, and Bayesian methods. All topics are organized well and all mathematical foundations are explained before being applied to neural networks. The text is suitable for a graduate or advanced undergraduate level course on neural networks or for practitioners interested in applying neural networks to real-world problems. The reader is assumed to have the level of math knowledge necessary for an undergraduate science degree. This is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts, the book examines techniques for modelling probability density functions and the properties and merits of the multi-layer perceptron and radial basis function network models. Also covered are various forms of error functions, principal algorithms for error function minimalization, learning and generalization in neural networks, and Bayesian techniques and their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved in the fields of neural computation and pattern recognition.},
    author = {Bishop, Christopher  M. },
    citeulike-article-id = {308856},
    howpublished = {Paperback},
    isbn = {0198538642},
    keywords = {artificial-intelligence book features},
    month = {November},
    priority = {0},
    publisher = {Oxford University Press},
    title = {Neural Networks for Pattern Recognition},
    url = {http://www.amazon.co.uk/exec/obidos/ASIN/0198538642/citeulike-21},
    year = {1995}
}
@book{grama2003,
    author = {A. Grama and A. Gupta and G. Karypis and V. Kumar},
    title = {Introduction to Parallel Computing},
    edition="Second",
    year = {2003},
    isbn = {0-201-64865-2},
    publisher = {Addison-Wesley},
    address = {Harlow, England},
}
@article{dean2004,
    abstract = {MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper.

Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system.

Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day.},
    address = {San Francisco, CA},
    author = {Dean, Jeffrey   and Ghemawat, Sanjay  },
    journal = {Sixth Symposium on Operating System Design and Implementation},
    citeulike-article-id = {120053},
    keywords = {applications data distributed google intensive},
    month = {November},
    priority = {0},
    title = {{MapReduce}: Simplified Data Processing on Large Clusters},
    url = {http://labs.google.com/papers/mapreduce.html},
    year = {2004}
}

@article{ schutte03parallel,
    author = "J. Schutte and J. Reinbolt and B. Fregly and R. Haftka and A. George",
    title = "Parallel Global Optimization with the Particle Swarm Algorithm",
    journal = "International Journal of Numerical Methods in Engineering",
    year = "2004",
    volume = "61",
    pages = "2296--2315",
    url = "citeseer.ist.psu.edu/schutte03parallel.html"
}

@article{ koh2006,
    author = "Byung-Il Koh and Alan D. George and Raphael T. Haftka and Benjamin J. Fregly",
    title = "Parallel asynchronous particle swarm optimization",
    journal = "International Journal of Numerical Methods in Engineering",
    year = "2006",
    volume = "67",
    pages = "578--595",
}

@inproceedings{ venter2005,
    author = "Gerhard Venter and Jaroslaw Sobieszczanski-Sobieski",
    title = "A Parallel Particle Swarm Optimization Algorithm Accelerated by Asynchronous Evaluations",
    booktitle = "Proceedings of the 6th World Congresses of Structural and Multidisciplinary Optimization",
    year = "2005",
}

@article{belal2004,
    author = "M. Belal and T. El-Ghazawi",
    title = "Parallel Models for Particle Swarm Optimizers",
    journal = "The International Journal of Intelligent Computing and Information Sciences",
    volume = "4",
    number = "1",
    pages = "100--111",
    year = "2004",
}

@techreport{mostaghim2006,
 author = {Sanaz Mostaghim and J{\"{u}}rgen Branke and Hartmut Schmeck},
 title = {Multi-Objective Particle Swarm Optimization on Computer Grids},
 institution = {AIFB Institute},
 number = {502},
 type = {Technical Report},
 month = {DEC},
 url = {\url{http://www.aifb.uni-karlsruhe.de/EffAlg/smo/paper-12-06.pdf}},
 year = {2006},
}

@article{jin2005,
    author = "Nanbo Jin and Yahya Rahmat-Samii",
    title = "Parallel particle swarm optimization and finite-difference time-domain (PSO/FDTD) algorithm for multiband and wide-band patch antenna designs",
    journal = "IEEE Transactions on Antennas and Propogation",
    volume = "53",
    number = "11",
    pages = "3459--3468",
    year = "2005",
}

@inproceedings{ parsopoulos04multiobjective,
  author = "K. Parsopoulos and D. Tasoulis and M. Vrahatis",
  title = "Multiobjective optimization using parallel vector evaluated particle swarm
    optimization",
  booktitle =  "Proceedings
    of the IASTED International Conference on Artificial Intelligence and Applications",
  year = "2004",
  url = "citeseer.ist.psu.edu/article/parsopoulos04multiobjective.html"
}


