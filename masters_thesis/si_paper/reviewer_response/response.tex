\documentclass[onecolumn, 12pt]{article}
\usepackage{fullpage}

\begin{document}

\section*{Associate Editor Comments}

\subsection*{AE.1}

Reviewer comments: The quality of the article will be improved if you include a
review of existing parallelization methods for PSO, to produce a kind of
taxonomy. Then, also include comparisons with these approaches. You currently
compare only with a naive approach and adaptations of your approach.

Response: We added a Related Work section (now section 3), describing previous
approaches at parallelizing PSO.  As we note in the paper, most of the related
work is orthogonal to innovations we describe, so it is difficult to determine
what other methods to compare against.  The majority of previous papers on the
parallelization of PSO deal with functions with very short evaluation times, so
they propose topologies that limit communication between processors on
different machines.  Those methods work very well for those functions, but when
you are dealing with functions whose evaluation takes over a second, the
benefits of the limited communication become negligible.  We did, however,
experiment with one of the topologies proposed for fast running functions.  We
found that in almost all cases simply using a Complete topology gave better
performance.  We make note of all of this in the paper, mostly in section 3.

\subsection*{AE.2}

Reviewer comments: Please indicate if differences in performance are
statistically significant.

Response: We restructured most of our results section, and now include
statistical significance in the form of bolded entries in a table.  This is
noted in the paper.

\subsection*{AE.3}

Reviewer comments: It will also be good if you do make use of problems where
parallelization has benefit. For the functions that you use, there is not real
not for parallelization. Linked to this, when will parallelization be
beneficial?

Response: We added a section dealing with this issue (section 7.1).  We also
added experiments on a function that takes on the order of 2 seconds to
evaluate, providing a little more motivation for the parallelization of PSO.

\subsection*{AE.4}

Reviewer comments: Please re-organize section 3: You start with a very long
theoretical discussion, and only then get to section 3.1.

Response: Good point.  We realized that we tried to cram too much into a single
section, so we split the two main parts of it into two separate sections.
There is now a section devoted entirely to the mathematics of the method (now
Section 4) and a separate section describing its implementation (Section 5).
We also put subsections in the new Section 4 to guide the reader a little
better through the section, and gave an intuitive description of speculative
evaluation before jumping into the math.

\section*{Reviewer 1 Comments}

\subsection*{1.1}

Reviewer comments: I'm a bit skeptical about the actual \emph{practical}
significance of the proposed method, [because it is difficult to know for any
given problem what the right swarm size is]. To be fair, this criticism applies
to most contributions focused on algorithms rather than on problems.

Response: This is a fair criticism, as it is true that experimentation with a
problem is required before one can know how best to solve it.  We added two
paragraphs to the end of section 2 to further make this point, making more
prominent reference to the No Free Lunch theorems.

\subsection*{1.2}

Reviewer comments: The organization and presentation of the ideas can be
greatly improved. The authors mix results and conclusions with the description
of the approach. This doesn't help the goal of the authors. A reader, cannot
appreciate the significance of some result or conclusion if he/she hasn't
understood what the authors are talking about. I recommend the authors to
restructure the whole paper but in particular Sections 3 and 4.

Response: We substantially reorganized Section 3, as noted above, and we added
more subsections throughout the paper, helping to guide the reader through the
ideas.  We believe that the paper is now much more clear.

\subsection*{1.3}

Reviewer comments: The notation used throughout the paper is confusing. In the
PSO literature, it is common to use x as a particles current position and some
other letters to denote a particle's personal best position and a particle's
neighborhood's best position. I know that the authors are using superscripts to
distinguish between these concepts but they don't really help.

Response: We had a long discussion about notation before writing our paper, and
we thought that because the personal best and neighborhood bests are positions,
using an x to denote it would be more intuitive.  However, we see your point
that it can be confusing for other reasons.  We changed the x to a b when
referring to best positions, while still using the N and P superscripts to
differentiate between which best is being referred to.

\subsection*{1.4}

Reviewer comments: Using ``rounds of evaluations'' is confusing, and results
should be reported in terms of wall clock time.

Response: Rounds of evaluations correspond exactly to wall clock time, as we
describe in what is now section 7.1, and the second paragraph of section 7
proper.  However, we realize that the term is not a commonly used one, so we
changed ``rounds of evaluations'' to ``time steps'' in hopes of better
conveying our meaning.  We also added some text in the description mentioned
above that hopefully further clarifies this point.

\subsection*{1.5}

Reviewer comments: Since the authors are using Herrera et al.'s proposed
benchmarks and since they are using a large computing cluster, I don't see why
they can't use the same experimental protocol proposed by Herrera et al., which
is focused on large scale optimization. That protocol would better justify a
parallel algorithm because a 1000-dimensional problem is intuitively more
difficult than the 20-dimensional problems the authors are currently using. As
a side product, the authors can actually compare the results of the pruned
versions (which in my eyes, are new PSO variants) with those of other
state-of-the-art algorithms.

Response: We ran quite a few more experiments to bring our results closer to
Herrera et al. experimental protocol.  Their protocol wasn't entirely
applicable, as they suggested running a specific number of function evaluations
instead of iterations (which, as we state in section 7, is the proper
comparison for parallel algorithms on long running functions).  But we added
experiments for 50 dimensional functions and 500 dimensional functions.

We also see your point in saying that our relaxations to speculative evaluation
are new PSO variants, and we fixed our text in places to better address that
point.  In particular, we changed the paragraph in the conclusion that deals
with this issue (``What we have presented\ldots''), clearly stating that our
methods do in fact change the behavior of PSO, but that they do so in a way
that is applicable to almost all PSO variants.  Thus a fair comparison is to
pick a particular variant and compare parallelization techniques with it.  It
made sense to pick the original PSO for this comparison.

\subsection*{1.6}

Reviewer comments: In the abstract, it is not clear the meaning of
``speculative''. A reader without knowledge about parallel computing may not
understand what the authors mean.

Response: We had a paragraph explaining this in the introduction, though the
analogy to processors lacked an explicit connection to the word
``speculative.''  We added a sentence at the end of that paragraph to address
this issue.

\subsection*{1.7}

Reviewer comments: The authors can cite Poli's paper about applications of PSO
algorithms in the first paragraph of the paper.

Response: We added the citation after the first sentence of the paper.

\subsection*{1.8}

Reviewer comments: What serves as the motivation for the authors's work is
insufficiently discussed.  The authors say that adding more particles leads to
``diminishing returns''. This may be true when dealing with constant size
populations.  However, a recent trend is to vary the population size over time.
In fact, it has been shown that adding particles \emph{over time} may actually
solve the problem the authors refer to. Some references are ``Incremental
Social Learning in Particle Swarms'' by Montes de Oca and others published in
IEEE SMCB and ``Efficient Population Utilization Strategy for Particle Swarm
Optimizer'' by Hsieh and others in the same journal.

Response: We added a paragraph in our related work section discussing these
methods (the last paragraph of the section).  We also added a paragraph to
future work discussing how these methods are particularly amenable to
speculative evaluation when parallelized (the second paragraph of the section).

\subsection*{1.9}

Reviewer comments: In the first paragraph of Section 3, the authors say that
adding particles may not help past a certain swarm size. This is true if the
computation time allocated to the optimization process remains fixed. However,
in some problems, it is the solution quality what matters. In that case, adding
particles \emph{and} computational budget may indeed be the best thing to do.

Response: This is very much related to the previous item, and so the response
to that item is relevant here.  We also added some text to to the introduction
(paragraph beginning with ``In this paper we consider\ldots'') to better
explain our intent; that is, given a fixed computational budget, how can
processors be used most efficiently?  The text we added in this and the
previous item addresses this question.

\subsection*{1.10}

Reviewer comments: In Eq. 3. Why must the current position be worse than the
neighbor's position?

Response: Your question probably arose from the confusing notation.  We have
fixed the notation and added a parenthetical statement directly preceeding the
equation to better explain what the equation is.  The equation is a specific
example of a possible update case, and in the case described the neighborhood
best is not updated; thus by definition the function values of current
positions must not be lower than the value of the previous neighborhood best.

\subsection*{1.11}

Reviewer comments: One or two step-by-step examples would greatly improve
Section 3.

Response: We fixed section 3 by splitting it into two sections and reorganizing
some parts, making the examples that were there more clear.  Hopefully the
section is satisfactory now.

\subsection*{1.12}

Reviewer comments: Isn't pruning against the idea of better using the available
computing resources? If one reduces the number of evaluated speculative
children, then fewer CPUs are going to be used.

Response: Pruning allows for the use of a larger swarm with the same number of
processors.  We realized that this was never explicitly stated in the text, so
we added a few sentences to the description of pruning (now section 6.2) to
make it clear.  The text added to the introduction explaining our purpose of
fully utilizing resources also addresses this issue, though somewhat
indirectly.

\subsection*{1.13}

Reviewer comments: Lines 29-30 of page 14. Stagnation is about the lack of
improvement of the best result. It has nothing to do with what the particles
are doing. I know that the PSO community confuses the two. I think this is a
nice opportunity to clarify the difference between search stagnation and the
state of the swarm.

Response: We were referring to the use of ``stagnation'' in analyses of the
sampling distribution of PSO (such as by Poli).  Our results show that the
``lack of improvement'' to which you refer does not in fact happen very often.
It is just that the scale of the improvements becomes increasingly smaller,
sometimes beyond machine precision.  We appreciate your distinction, however.
Such a definition of stagnation must then incorporate a minimum velocity, which
is another function-dependent parameter to specify.  We decided that the
paragraph dealing with this issue was at best tangential to the focus of our
paper and that it unnecessarily lengthened an already lengthy discussion.  We
removed the paragraph from our text.

\subsection*{1.14}

Reviewer comments: All figures are not clear. The authors should find line
styles that are more distinguishable.

Response: ...

NOT DONE

\subsection*{1.15}

Reviewer comments: Page 27, line 40. Algorithms are suited for problems not the
other way around.

Response: Duly noted.  We fixed the sentence, then in a later revision took out
that discussion entirely, making the conclusion less repetitive.

\subsection*{1.16}

Reviewer comments: Page 31. Line 46. Molia $\rightarrow$ Molina. Is it a
technical report?  Which number?  Isn't it published with the special issue?

Response:  We fixed the typo, and we looked for quite some time trying to find
a better way to cite that paper.  The special issue hasn't been officially
published yet, from what I can tell, and the editorial that is online (under
``Online First'' at springerlink.com) only has a link to the test suite
document.  I suppose that we could cite the editorial instead of the test suite
document, if you think that would be preferable.

\section*{Reviewer 2 Comments}

I found the idea very interesting and the paper well-written. However, there
are still some points that need further investigation.  As far as I am
concerned, the paper has merit and shall be accepted after a revision that will
address these remarks.

\subsection*{2.1}

Reviewer comments: How does it scale with the problem's dimension? There is
experimental evidence that the required swarm size for achieving a prescribed
accuracy in a specific problem, increases almost exponentially with its
dimension. The proposed idea can make this necessity milder. Is there any
evidence on how well it scales when dimension increases? (e.g. probably the
increase in the required number of particles is closer to the linear rather
than the exponential case).

Response: We did not share your intuition about our methods improving PSO's
performance on higher dimensional functions.  However, we ran experiments to
test their scalability, as you suggested, and found them to perform very well
as dimensionality increased.  We are not entirely sure as to the reason for
this, though we gave some intuitive arguments based on brief experimentation.
The results and discussion are in the paper.

\subsection*{2.2}

Reviewer comments: In the first sections of the paper it is argued that the
proposed ``...method can easily be extended to arbitrary topologies''. However,
in later sections it is apparent that this may be possible if the underlying
neighborhood topology is not ``dense'' enough to cause heavy communication
traffic to the processors.  Can you be more precise to this and quantify it?
For example, given a swarm size and a common network communication is there any
identifiable limit to the neighborhood topology such that the algorithm retains
an acceptable performance?

Response: You seem to have been conflating two separate issues, and we changed
our text to help future readers not run into the same problem.  When we said
that our method ``can be easily extended to arbitrary topologies,'' we were
referring specifically to the math; we only showed one case, to simplify our
notation.  In fact our implementation handles arbitrary topologies.  One thing
that we realized, however, was that with pruning one can use arbitrarily dense
topologies without increasing the number of speculative evaluations at all.  We
thus ran more experiments to test the use of these topologies with pruned
speculative methods, and we now report those results in the paper.

\subsection*{2.3}

Reviewer comments: My personal experience with the PSO versions used in the
paper suggests that, in large dimensions, it is preferrable to use larger
swarms for less iterations rather than small swarms for more iterations. This
is in contrast to the argued behavior of PSO for the Sphere function (Section
1).  Did you observe the same behavior in other functions?  Could you provide
some evidence on this because, due to the swarm's diversity loss, it seems
somehow counterintuitive.

Response: The citation given in the paper (McNabb et al. CEC 09) gives an
interesting discussion on these points.  The functions explored there are
limited, but the paper shows that both Sphere and Griewank exhibit this
behavior, while Rastrigin does not (the relevant figures in that paper are 2, 4
and 6).  As those results are previously published and cited in our paper, we
felt it unnecessary to reduplicate the figures, though we make mention of the
conclusions.  However, our own figures also answer your question.  The fact
that our methods outperform the na\"ive parallelization is in itself evidence
for this claim.  Recall that when our figures say SEPSO, that is equivalent to
running PSO with a swarm size one eighth the size, doing twice as many
iterations.  Figures 9 and 10 illustrate the point that for some swarm sizes
you are correct and it is better to have a larger swarm size.  However, once
enough processors are available to have a large enough swarm even with SEPSO,
it is better by far to do speculative evaluation.

Increasing the swarm size increases the diversity, as you say (the McNabb et
al. paper makes the same point).  But at some point there is enough diversity,
and when that point is reached extra processors should be used for speculative
evaluation.  We spend a good amount of the conclusion trying to make this
point.

\section*{Reviewer 3 Comments}

\subsection*{3.1}

Reviewer comments: There are too many redundancy sentences declaring this paper
is not proposing a new algorithm in the introduction.

Response: We found only one part of the introduction that mentioned the paper
not proposing a new algorithm.  That part had two sentences, and we deleted the
second one to soften the point a little.  It was an over-reaction to comments
by previous reviewers.  We also fixed a similar statement in the conclusion.

\subsection*{3.2}

Reviewer comments: The velocity updating formular is different from the
original PSO algorithm.  The weighting factor, X, should only affects the old
velocity, not all the items.

Response: You are referring to inertia weight PSO (the original equations in
Kennedy 1995 did not have any weighting factor).  Constricted PSO is also a
widely used improvement on the original PSO, and we cite two papers as
justification for our use of those formulas.  However, our text wasn't clear
that we were using the constricted PSO equations, so we clarified the text.

\subsection*{3.3}

Reviewer comments: Some reference are not completed. For example, the
journal/conference name of the 4th reference is missing. Please check it
carefully.

Response: Thanks for catching that.  We fixed it and went over our other
references carefully.

\subsection*{3.4}

Reviewer comments: Please increasing the reference to extend the integrity of
the background.

Response: The Chu et al. paper that we already cite seems to be an extension of
the Chang et al. paper you mentioned.  However, we included the Chang et al.
paper along with the Chu et al. paper in our review of related work.  We also
included several more related papers in our review of current parallelization
strategies for PSO.

\end{document}
