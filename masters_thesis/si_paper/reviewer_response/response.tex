\documentclass[onecolumn, 12pt]{article}
\usepackage{fullpage}

\begin{document}

\section*{Associate Editor Comments}

\subsection*{AE.1}

Reviewer comments: The quality of the article will be improved if you include a
review of existing parallelization methods for PSO, to produce a kind of
taxonomy. Then, also include comparisons with these approaches. You currently
compare only with a naive approach and adaptations of your approach.

Response: We added a Related Work section (now section 3), describing previous
approaches at parallelizing PSO.  We also added (NOT DONE) experiments
comparing against another common parallelization approach, that of using
subswarms.

NOT DONE

\subsection*{AE.2}

Reviewer comments: Please indicate if differences in performance are
statistically significant.

Response: Because all of the these finished before all of these, the t-test
gave \ldots

NOT DONE

\subsection*{AE.3}

Reviewer comments: It will also be good if you do make use of problems where
parallelization has benefit. For the functions that you use, there is not real
not for parallelization. Linked to this, when will parallelization be
beneficial?

Response: We added a paragraph to what is now Section 7 addressing the issue of
benchmark functions (``We also do not report\ldots'').  We also ran a
comparison on a longer-running function and included it in our results (NOT
DONE).

NOT DONE

\subsection*{AE.4}

Reviewer comments: Please re-organize section 3: You start with a very long
theoretical discussion, and only then get to section 3.1.

Response: Good point.  We realized that we tried to cram too much into a single
section, so we split the two main parts of it into two separate sections.
There is now a section devoted entirely to the mathematics of the method (now
Section 4) and a separate section describing its implementation (Section 5).
We also put subsections in the new Section 4 to guide the reader a little
better through the section, and gave an intuitive description of speculative
evaluation before jumping into the math.

\section*{Reviewer 1 Comments}

\subsection*{1.1}

Reviewer comments: I'm a bit skeptical about the actual \emph{practical}
significance of the proposed method, [because it is difficult to know for any
given problem what the right swarm size is]. To be fair, this criticism applies
to most contributions focused on algorithms rather than on problems.

Response: This is a fair criticism, as it is true that experimentation with a
problem is required before one can know how best to solve it.  We added two
paragraphs to the end of section 2 to further make this point, making more
prominent reference to the No Free Lunch theorems.

\subsection*{1.2}

Reviewer comments: The organization and presentation of the ideas can be
greatly improved. The authors mix results and conclusions with the description
of the approach. This doesn't help the goal of the authors. A reader, cannot
appreciate the significance of some result or conclusion if he/she hasn't
understood what the authors are talking about. I recommend the authors to
restructure the whole paper but in particular Sections 3 and 4.

Response: We substantially reorganized Section 3, as noted above, and we moved
the discussion of branch statistics (the old Section 4.3) to the beginning of
the results section (NOT DONE).

NOT DONE

\subsection*{1.3}

Reviewer comments: The notation used throughout the paper is confusing. In the
PSO literature, it is common to use x as a particles current position and some
other letters to denote a particle's personal best position and a particle's
neighborhood's best position. I know that the authors are using superscripts to
distinguish between these concepts but they don't really help.

Response: We had a long discussion about notation before writing our paper, and
we thought that because the personal best and neighborhood bests are positions,
using an x to denote it would be more intuitive.  However, we see your point
that it can be confusing for other reasons.  We changed the x to a b when
referring to best positions, while still using the N and P superscripts to
differentiate between which best is being referred to.

\subsection*{1.4}

Reviewer comments: Using ``rounds of evaluations'' is confusing, and results
should be reported in terms of wall clock time.

Response: Rounds of evaluations correspond exactly to wall clock time, as we
describe in the second paragraph of what was Section 5 (now Section 7).
However, we realize that the term is not a commonly used one, so we changed
``rounds of evaluations'' to ``time steps'' in hopes of better conveying our
meaning.  We also added some text in the description mentioned above that
hopefully further clarifies this point.

\subsection*{1.5}

Reviewer comments: Since the authors are using Herrera et al.'s proposed
benchmarks and since they are using a large computing cluster, I don't see why
they can't use the same experimental protocol proposed by Herrera et al., which
is focused on large scale optimization. That protocol would better justify a
parallel algorithm because a 1000-dimensional problem is intuitively more
difficult than the 20-dimensional problems the authors are currently using. As
a side product, the authors can actually compare the results of the pruned
versions (which in my eyes, are new PSO variants) with those of other
state-of-the-art algorithms.

Response: Running a few more sets of experiments at higher dimensionalities
should address this adequately, though we can't really do all of their
protocol.

NOT DONE

\subsection*{1.6}

Reviewer comments: In the abstract, it is not clear the meaning of
``speculative''. A reader without knowledge about parallel computing may not
understand what the authors mean.

Response: We had a paragraph explaining this in the introduction, though the
analogy to processors lacked an explicit connection to the word
``speculative.''  We added a sentence at the end of that paragraph to address
this issue.

\subsection*{1.7}

Reviewer comments: The authors can cite Poli's paper about applications of PSO
algorithms in the first paragraph of the paper.

Response: We added the citation after the first sentence of the paper.

\subsection*{1.8}

Reviewer comments: What serves as the motivation for the authors's work is
insufficiently discussed.  The authors say that adding more particles leads to
``diminishing returns''. This may be true when dealing with constant size
populations.  However, a recent trend is to vary the population size over time.
In fact, it has been shown that adding particles \emph{over time} may actually
solve the problem the authors refer to. Some references are ``Incremental
Social Learning in Particle Swarms'' by Montes de Oca and others published in
IEEE SMCB and ``Efficient Population Utilization Strategy for Particle Swarm
Optimizer'' by Hsieh and others in the same journal.

Response: We added a paragraph in our related work section discussing these
methods (the last paragraph of the section).  We also added a paragraph to
future work discussing how these methods are particularly amenable to
speculative evaluation when parallelized (the second paragraph of the section).

\subsection*{1.9}

Reviewer comments: In the first paragraph of Section 3, the authors say that
adding particles may not help past a certain swarm size. This is true if the
computation time allocated to the optimization process remains fixed. However,
in some problems, it is the solution quality what matters. In that case, adding
particles \emph{and} computational budget may indeed be the best thing to do.

Response: This is very much related to the previous item, and so the response
to that item is relevant here.  We also added some text to to the introduction
(paragraph beginning with ``In this paper we consider\ldots'') to better
explain our intent; that is, given a fixed computational budget, how can
processors be used most efficiently?  The text we added in this and the
previous item addresses this question.

\subsection*{1.10}

Reviewer comments: In Eq. 3. Why must the current position be worse than the
neighbor's position?

Response: Your question probably arose from the confusing notation.  We have
fixed the notation and added a parenthetical statement directly preceeding the
equation to better explain what the equation is.  The equation is a specific
example of a possible update case, and in the case described the neighborhood
best is not updated; thus by definition the function values of current
positions must not be lower than the value of the previous neighborhood best.

\subsection*{1.11}

Reviewer comments: One or two step-by-step examples would greatly improve
Section 3.

Response: We fixed section 3 by splitting it into two sections and reorganizing
some parts, making the examples that were there more clear.  Hopefully the
section is satisfactory now.

\subsection*{1.12}

Reviewer comments: Isn't pruning against the idea of better using the available
computing resources? If one reduces the number of evaluated speculative
children, then fewer CPUs are going to be used.

Response: Pruning allows for the use of a larger swarm with the same number of
processors.  We realized that this was never explicitly stated in the text, so
we added a few sentences to the description of pruning (now section 6.2) to
make it clear.  The text added to the introduction explaining our purpose of
fully utilizing resources also addresses this issue, though somewhat
indirectly.

\subsection*{1.13}

Reviewer comments: Lines 29-30 of page 14. Stagnation is about the lack of
improvement of the best result. It has nothing to do with what the particles
are doing. I know that the PSO community confuses the two. I think this is a
nice opportunity to clarify the difference between search stagnation and the
state of the swarm.

Response: In fact the best result is improved, frequently, it is just that the
scale of the improvements becomes increasingly smaller.

NOT DONE

\subsection*{1.14}

Reviewer comments: All figures are not clear. The authors should find line
styles that are more distinguishable.

Response: ...

NOT DONE

\subsection*{1.15}

Reviewer comments: Page 27, line 40. Algorithms are suited for problems not the
other way around.

Response: Duly noted.  We fixed the sentence (it now says ``Our methods work
very well on these functions'').

\subsection*{1.16}

Reviewer comments: Page 31. Line 46. Molia $\rightarrow$ Molina. Is it a
technical report?  Which number?  Isn't it published with the special issue?

Response:  We fixed the typo, and we looked for quite some time trying to find
a better way to cite that paper.  The special issue hasn't been officially
published yet, from what I can tell, and the editorial that is online (under
``Online First'' at springerlink.com) only has a link to the test suite
document.  I suppose that we could cite the editorial instead of the test suite
document, if you think that would be preferable.

\section*{Reviewer 2 Comments}

I found the idea very interesting and the paper well-written. However, there
are still some points that need further investigation.  As far as I am
concerned, the paper has merit and shall be accepted after a revision that will
address these remarks.

\subsection*{2.1}

Reviewer comments: How does it scale with the problem's dimension? There is
experimental evidence that the required swarm size for achieving a prescribed
accuracy in a specific problem, increases almost exponentially with its
dimension. The proposed idea can make this necessity milder. Is there any
evidence on how well it scales when dimension increases? (e.g. probably the
increase in the required number of particles is closer to the linear rather
than the exponential case).

Response: ...

NOT DONE

\subsection*{2.2}

Reviewer comments: In the first sections of the paper it is argued that the
proposed ``...method can easily be extended to arbitrary topologies''. However,
in later sections it is apparent that this may be possible if the underlying
neighborhood topology is not ``dense'' enough to cause heavy communication
traffic to the processors.  Can you be more precise to this and quantify it?
For example, given a swarm size and a common network communication is there any
identifiable limit to the neighborhood topology such that the algorithm retains
an acceptable performance?

Response: ...

NOT DONE

\subsection*{2.3}

Reviewer comments: My personal experience with the PSO versions used in the
paper suggests that, in large dimensions, it is preferrable to use larger
swarms for less iterations rather than small swarms for more iterations. This
is in contrast to the argued behavior of PSO for the Sphere function (Section
1).  Did you observe the same behavior in other functions?  Could you provide
some evidence on this because, due to the swarm's diversity loss, it seems
somehow counterintuitive.

Response: The citation given in the paper (McNabb et al. CEC 09) gives an
interesting discussion on these points.  The functions explored are limited,
but the paper shows that both Sphere and Griewank exhibit this behavior, while
Rastrigin does not (the relevant figures in that paper are 2, 4 and 6).  As
those results are previously published and cited in our paper, we felt it
unnecessary to reduplicate the figures, though we make mention of the
conclusions.  However, our own figures also answer your question.  The fact
that our methods outperform the na\"ive parallelization is in itself evidence
for this claim.  Recall that when our figures say SEPSO, that is equivalent to
running PSO with a swarm size one eighth the size, doing twice as many
iterations.  Figures 9 and 10 illustrate the point that for some swarm sizes
you are correct and it is better to have a larger swarm size.  However, once
enough processors are available to have a large enough swarm even with SEPSO,
it is better by far to do speculative evaluation.

Increasing the swarm size increases the diversity, as you say (the McNabb et
al. paper makes the same point).  But at some point there is enough diversity,
and when that point is reached extra processors should be used for speculative
evaluation.  We spend almost the entire conclusion trying to make this point.

\section*{Reviewer 3 Comments}

\subsection*{3.1}

Reviewer comments: There are too many redundancy sentences declaring this paper
is not proposing a new algorithm in the introduction.

Response: We found only one part of the introduction that mentioned the paper
not proposing a new algorithm.  That part had two sentences, and we deleted the
second one to soften the point a little.  It was an over-reaction to comments
by previous reviewers.

\subsection*{3.2}

Reviewer comments: The velocity updating formular is different from the
original PSO algorithm.  The weighting factor, X, should only affects the old
velocity, not all the items.

Response: You are referring to inertia weight PSO (the original equations in
Kennedy 1995 did not have any weighting factor).  Constricted PSO is also a
widely used improvement on the original PSO, and we cite two papers as
justification for our use of those formulas.  However, our text wasn't clear
that we were using the constricted PSO equations, so we clarified the text.

\subsection*{3.3}

Reviewer comments: Some reference are not completed. For example, the
journal/conference name of the 4th reference is missing. Please check it
carefully.

Response: Thanks for catching that.  We fixed it and went over our other
references carefully.

\subsection*{3.4}

Reviewer comments: Please increasing the reference to extend the integrity of
the background.

Response: The Chu et al. paper that we already cite seems to be an extension of
the Chang et al. paper you mentioned.  However, we included the Chang et al.
paper along with the Chu et al. paper in our review of related work.  We also
included several more related papers in our review of current parallelization
strategies for PSO.

\end{document}
