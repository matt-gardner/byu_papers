\documentclass[ms]{byuprop}
% Options for this class include the following (* indicates default):
%
%   10pt -- 10 point font size
%   11pt -- 11 point font size
%   12pt (*) -- 12 point font size
%
%   ms -- produce a thesis proposal (off)
%   areaexam -- produce a research area overview (off)
%   phd -- produce a dissertation proposal (off)
%   
%   layout -- show layout lines on the pages, helps with overfull boxes (off)
%   grid -- show a half-inch grid on every page, helps with printing (off)


% This command fixes my particular printer, which starts 0.03 inches too low,
% shifting the whole page down by that amount.  This shifts the document
% content up so that it comes out right when printed.
%
% Discovering this sort of behavior is best done by specifying the ``grid''
% option in the class parameters above.  It prints a 1/2 inch grid on every
% page.  You can then use a ruler to determine exactly what the printer is
% doing.
%
% Uncomment to shift content up (accounting for printer problems)
%\setlength{\voffset}{-.03in}

% Here we set things up for invisible hyperlinks in the document.  This makes
% the electronic version clickable without changing the way that the document
% prints.  It's useful, but optional.
\usepackage[
    ps2pdf,
    bookmarks=true,
    breaklinks=true,
    raiselinks=true,
    pdfborder={0 0 0},
    colorlinks=false,
    ]{hyperref}

% Rewrite the itemize, description, and enumerate environments to have more
% reasonable spacing:
\newcommand{\ItemSep}{\itemsep 0pt}
\let\oldenum=\enumerate
\renewcommand{\enumerate}{\oldenum \ItemSep}
\let\olditem=\itemize
\renewcommand{\itemize}{\olditem \ItemSep}
\let\olddesc=\description
\renewcommand{\description}{\olddesc \ItemSep}

% Get a little less fussy about word spacing on a line.  Sometimes produces
% ugly results, so keep your eyes peeled.
\sloppy

% Important settings for the byuprop class. %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Because I use these things in more than one place, I created new commands for
% them.  I did not use \providecommand because I absolutely want LaTeX to error
% out if these already exist.
\newcommand{\Title}{A Speculative Approach to Parallelization in Particle Swarm
Optimization}
\newcommand{\Author}{Matthew Gardner}
\newcommand{\SubmissionMonth}{February}
\newcommand{\SubmissionYear}{2011}

% Take these from the commands defined above
\title{\Title}
\author{\Author}
\monthsubmitted{\SubmissionMonth}
\yearsubmitted{\SubmissionYear}

% Committee members
\committeechair{Kevin Seppi}
\committeemembera{Eric Ringger}
\committeememberb{David Embley}
%\committeememberc{}
%\committeememberd{}

% Department graduate coordinator
\graduatecoordinator{Kent Seamons}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Set up the internal PDF information so that it becomes part of the document
% metadata.  The pdfinfo command will display this. Be sure to set the document
% type and add your own keywords.
\hypersetup{%
    pdftitle=\Title,%
    pdfauthor=\Author,%
    pdfsubject={Masters thesis proposal, BYU CS Department: %
                Submitted \SubmissionMonth~\SubmissionYear, Created \today},%
    pdfkeywords={parallel algorithms, optimization methods, particle swarm %
				optimization, speculative decomposition},%
}

% These packages allow the bibliography to be sorted alphabetically and allow references to more than one paper to be sorted and compressed (i.e. instead of [5,2,4,6] you get [2,4-6])
\usepackage{url}
\usepackage[numbers,sort&compress]{natbib}
\bibliographystyle{annotnat}
\usepackage{hypernat}
% Note, use \citet to name the authors (text mode) and \citep to do just give
% the number (parenthetical mode).  Also, \citep* will give all of the authors
% rather than an abbreviated list.

% Additional packages required for your specific thesis go here. I've left some I use as examples.
\usepackage{graphicx}
\usepackage{psfrag}
%\usepackage{pdfsync}
\usepackage{amsmath}

% Better references, I think
\newcommand{\secref}[1]{Section~\ref{sec:#1}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\algref}[1]{Algorithm~\ref{alg:#1}}

%% PSO Stuff
\DeclareMathOperator*{\argmin}{arg\;min}
\DeclareMathOperator*{\argmax}{arg\;max}
\DeclareMathOperator*{\arginf}{arg\;inf}
\DeclareMathOperator*{\argsup}{arg\;sup}
\providecommand{\pers}{\ensuremath{P}}
\providecommand{\neigh}{\ensuremath{N}}
\providecommand{\leftind}{\ensuremath{L}}
\providecommand{\rightind}{\ensuremath{R}}
\providecommand{\nURand}{\ensuremath{U^\neigh}}
\providecommand{\pURand}{\ensuremath{U^\pers}}
\providecommand{\ppos}{\ensuremath{\Vec{x}}}
\providecommand{\fppos}{\ensuremath{\Vec{fx}}}
\providecommand{\pvel}{\ensuremath{\Vec{v}}}
\providecommand{\nbest}{\ensuremath{\Vec{b}^\neigh}}
\providecommand{\fnbest}{\ensuremath{\Vec{fb}^\neigh}}
\providecommand{\pbest}{\ensuremath{\Vec{b}^\pers}}
\providecommand{\fpbest}{\ensuremath{\Vec{fb}^\pers}}
\providecommand{\constriction}{\ensuremath{\chi}}
\providecommand{\ncoeff}{\ensuremath{\phi^\neigh}}
\providecommand{\pcoeff}{\ensuremath{\phi^\pers}}
\providecommand{\obs}{\ensuremath{\Vec{\xi}}}
\providecommand{\ofunc}{\ensuremath{f}}
\providecommand{\swarm}{\ensuremath{swarm}}

%SpecExPSO Stuff
\providecommand{\indic}{\ensuremath{I}}
\providecommand{\specvel}{\ensuremath{\vec{V}}}
\providecommand{\specpos}{\ensuremath{\vec{X}}}
\providecommand{\leftn}{\ensuremath{\Vec{x}^\leftind}}
\providecommand{\rightn}{\ensuremath{\Vec{x}^\rightind}}
\providecommand{\caseset}{\ensuremath{\mathcal{C}}}
\providecommand{\casegen}{\ensuremath{c}}
\providecommand{\casedef}{\ensuremath{(\pbest,\nbest)}}
\providecommand{\casexn}{\ensuremath{(S,-)}}
\providecommand{\casexx}{\ensuremath{(S,S)}}
\providecommand{\casexl}{\ensuremath{(S,\leftind)}}
\providecommand{\casexr}{\ensuremath{(S,\rightind)}}
\providecommand{\casepn}{\ensuremath{(-,-)}}
\providecommand{\casepl}{\ensuremath{(-,\leftind)}}
\providecommand{\casepr}{\ensuremath{(-,\rightind)}}
\providecommand{\casepN}{\ensuremath{(-,N)}}
\providecommand{\casexN}{\ensuremath{(S,N)}}
\providecommand{\noeval}[1]{\ensuremath{#1^{-e}}}
\providecommand{\nonbest}[1]{\ensuremath{#1^{-n}}}
\providecommand{\p}{\ensuremath{p}}
\providecommand{\pset}{\ensuremath{\mathbf{p}}}
\providecommand{\s}{\ensuremath{s}}
\providecommand{\sset}{\ensuremath{\mathbf{s}}}
\providecommand{\nsset}{\ensuremath{\mathbf{ns}}}
\providecommand{\n}{\ensuremath{n}}
\providecommand{\nset}{\ensuremath{\mathbf{n}}}
\providecommand{\nnset}{\ensuremath{\mathbf{nn}}}

%Other math
\providecommand{\prob}{\ensuremath{\mathrm{Pr}}}


\begin{document}

% Produce the preamble
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Abstract}
% 1 to 2 paragraphs

Particle swarm optimization (PSO) has previously been parallelized primarily by
distributing the computation corresponding to particles across multiple
processors.  In these approaches, additional processors can only add more
particles to the swarm.  However, in many cases this is not efficient when
scaled to very large swarm sizes (on very large clusters).  Current methods
cannot answer well the question, ``What do you do with 1000 processors when 50
or 100 particles is the most efficient swarm size?''  In this paper we attempt
to answer that question with a speculative approach to the parallelization of
PSO motivated by speculative execution in modern computer hardware.

In our approach, we refactor PSO such that the computation needed for iteration
$t+1$ can be done in parallel with the computation needed for iteration $t$.
Thus we can perform two iterations of PSO at once.  Even with some amount of
wasted computation, we show that this approach to parallelization in PSO often
outperforms the na\"ive parallelization of simply adding particles to the
swarm.  Our methods produce results that are exactly equivalent to PSO; this is
not a new algorithm or variant, only a new method of parallelization.

However, given this new parallelization model we can relax the requirement of
exactly reproducing PSO in an attempt to produce better results.  We present
several such relaxations, including keeping the best speculative position
evaluated instead of the one corresponding to PSO, and speculating several
iterations ahead instead of just one.  We show that these methods dramatically
improve the performance of parallel PSO in many cases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
% 1 to 4 pages
\label{sec:intro}

Particle swarm optimization (PSO) has been found to be a highly robust and
effective algorithm for solving many types of optimization
problems~\citep{poli-2008-pso-applications}.  For much of the algorithm's
history, PSO was run serially on a single machine.  However, the world's
computing power is increasingly coming from large clusters of processors.  In
order to efficiently utilize these resources for computationally intensive
problems, PSO needs to run in parallel.

Within the last few years, researchers have begun to recognize the need to
develop parallel implementations of PSO, publishing many papers on the subject.
The methods they have used include various synchronous algorithms
\citep{chu-2006-intelligent-parallel-pso,jin-2005-pso-antenna-designs,%
parsopoulos-2004-parallel-vector-evaluated-pso,%
schutte-2004-parallel-global-optimization-with-pso} and asynchronous algorithms
\citep{mostaghim-2006-multi-objective-pso-on-grids,%
venter-2005-parallel-pso-asynchronous-evaluations}.  Parallelizing the
evaluation of the objective function can also be done in some cases, though
that is not an adaption of the PSO algorithm itself and thus is not the focus
of this paper.

These previous parallel techniques distribute the computation needed by the
particles in the swarm over the available processors.  If more processors are
available, these techniques increase the number of particles in the swarm,
either by adding individual particles or by adding entire new sub-swarms.  In
almost all cases, adding additional particles produces better results in the
same amount of time~\citep{mcnabb-2009-large-particle-swarms}.  In
\figref{iters-sphere} we see an example of this on the well-known benchmark
function Sphere (20 dimensions, reporting the average of twenty runs).  In
terms of the number of iterations performed (which is equivalent to wall-clock
time if all particles are evaluated in parallel), every time the swarm size
increases, the performance improves.

\begin{figure}
  \centering
  \includegraphics[width=.8\columnwidth]{iters_sphere}
  \caption{Function Sphere with various swarm sizes, comparing performance with
  the number of iterations of the algorithm performed.}
  \label{fig:iters-sphere}
\end{figure}

However, it can be seen from the graph that once the swarm is sufficiently
large, doubling the swarm size produces only incremental benefit; performance
improves, but not by very much.  The reason for this is that there comes a
point of diminishing returns with respect to adding particles.  In
\figref{evals-sphere} we show the value obtained after 50,000 function
evaluations (not iterations) as a function of swarm size, again for the
function Sphere.  Increasing the swarm size from 5 to 10 has a significant
effect on the value obtained.  However, increasing the swarm size from 16 to 30
makes the algorithm less efficient; that is, it reduces the progress the
algorithm makes per evaluation.  Other functions show similar trends, though
often the optimal swarm size is slightly larger.  For this reason, previous
work has recommended the use of a swarm size of 50 for
PSO~\citep{bratton-2007-defining-a-standard-for-pso}.  Thus, in at least some
cases, adding particles indefinitely will not yield an efficient
implementation. 

\begin{figure}
  \centering
  \includegraphics[width=.8\columnwidth]{evals_sphere}
  \caption{Function Sphere with various swarm sizes, comparing performance with
  the number of function evaluations performed.  Error bars show median and
  10th and 90th percentiles.}
  \label{fig:evals-sphere}
\end{figure}

In this project we consider PSO parallelization strategies for clusters of
hundreds or thousands of processors and functions for which a single evaluation
will take at least tens of seconds, but probably minutes or perhaps hours.  Our
purpose is to explore the question of what to do with a thousand processors
when 50 or 100 particles is the most efficient swarm size, and simply adding
particles results in only incremental improvement.  In our work we assume that
the researcher has some fixed number of processors that should be fully
utilized throughout the optimization process.

In order to solve this problem, we apply the concept of speculative
decomposition~\citep{grama-2003-intro-to-parallel-computing} to particle swarm
optimization, using extra processors to perform two iterations of PSO at the
same time.  Speculative decomposition is analogous to speculative execution
(also known as branch prediction), a technique commonly used in processors.
Modern processors, when faced with a branch on which they must wait (e.g., a
memory cache miss), guess which way the branch will go and start executing,
ensuring that any changes can be undone.  If the processor guesses right,
execution is much farther ahead than if it had idly waited on the memory
reference.  If it guesses wrong, execution restarts where it would have been
anyway.  Thus the processor speculates about future paths of execution in an
attempt to decrease overall processing time.

In this paper we show that the results of standard PSO can be reproduced
\emph{exactly}, two iterations at a time, using a speculative approach adapted
from speculative execution. We prove that the standard PSO equation can be
factored such that a set of speculative positions can be found which will
always include the position computed in the next iteration.  By computing the
value of the objective function for each of the speculative positions at the
same time the algorithm evaluates the objective function for the current
position, it is possible to know the objective function values for both the
current and the next iteration at the same time.  We demonstrate this principle
by implementation and show that it produces exactly the same results as
standard PSO, but two iterations at a time.  The resulting implementation runs
efficiently on large clusters where the number of processors is much larger
than a typical or reasonable number of particles, producing better results in
less ``wall-clock'' time.

It is important to note here that this is not a variant of PSO.  We simply
propose a new way to think about the parallelization of PSO that we show
performs better in many cases than previous parallelizations.

Furthermore, we show that if we relax the requirements of the algorithm, no
longer demanding that it strictly reproduce the exact behavior of standard PSO,
we can introduce new speculative techniques that often out-perform na\"ive
parallelizations of PSO.  These relaxations make better use of the information
obtained from the extra exploration made by the speculative function
evaluations.  We also explore the idea that, like branch prediction in
processors, we need not speculatively evaluate \emph{all} possible future
positions, we can accelerate the algorithm even if we are just \emph{likely} to
have guessed right.  By pruning the speculation to just paths that are
statistically likely to reproduce the paths that are equivalent to PSO we can
increase the swarm size without increasing the number of speculative
evaluations.  We also consider several recovery strategies for cases where the
pruned set of speculative evaluations does not contain the evaluation that
standard PSO would have done.  A further improvement we explore is speculating
several iterations ahead instead of just one, which is made possible by pruning
the number of speculative evaluations.

\subsection{Particle Swarm Optimization}
\label{sec:pso}

Particle swarm optimization was proposed in 1995 by James Kennedy and Russell
Eberhart~\citep{kennedy-1995-particle-swarm-optimization}.  The algorithm is
used to intelligently search a multi-dimensional space by mimicking the
swarming and flocking behavior of birds and other animals. It is a social
algorithm that depends on interaction between particles to quickly and
consistently approximate the optimal solution to a given objective function.

The motion of particles through the search space has three components: an
inertial component that gives particles momentum as they move, a cognitive
component where particles remember the best solution they have found and are
attracted back to that place, and a social component by which particles are
attracted to the best solution that any of their neighbors have found.

At each iteration of constricted PSO, the position $\ppos_t$ and velocity
$\pvel_t$ of each particle are updated as follows:
\begin{align}
\label{eq:velupdate}
	\pvel_{t+1} &=
		\constriction \bigl[ \pvel_t
			+ \pcoeff\pURand_{t}\otimes(\pbest_{t} - \ppos_{t}) +
			\ncoeff\nURand_{t}\otimes(\nbest_{t} - \ppos_{t})
		\bigr] \\
\label{eq:posupdate}
	\ppos_{t+1} &= \ppos_{t} + \pvel_{t+1}
\end{align}
where \( \pURand_{t} \) and \( \nURand_{t} \) are vectors of independent random
numbers drawn from a standard uniform distribution, the \( \otimes \) operator
is an element-wise vector multiplication, $\pbest$ (called personal best) is
the best position the current particle has seen, and $\nbest$ (called
neighborhood best) is the best position the neighbors of the current particle
have seen~\citep{bratton-2007-defining-a-standard-for-pso}.  The parameters \(
\ncoeff \), \( \pcoeff \), and \( \constriction \) are given prescribed values
required to ensure convergence (2.05, 2.05, and .73,
respectively)~\citep{clerc-2002-constricted-pso}. 

Changing the way neighbors are defined, usually called the ``topology,'' has a
significant effect on the performance of the algorithm.  In the Ring topology,
each particle has one neighbor to either side of it; in the Complete
topology\footnote{The Complete topology has often been unfortunately named Star
in the literature, which in graph theory refers to a completely different
topology.  Other names have also been used, including ``global topology'' and
gbest.  We use the graph theory term ``Complete'' in this paper.}, every
particle is a neighbor to every other
particle~\citep{bratton-2007-defining-a-standard-for-pso}.  In all topologies a
particle is also a neighbor to itself in that its own position and value are
considered when updating the particle's neighborhood best, $\nbest$.  Thus with
$p$ particles, using the Ring topology each particle with index $i$ has three
neighbors: $i-1$, $i$ (itself), and $i+1$.  With the Complete topology, each
particle has $p$ neighbors.

In this paper we use these topologies as well as a parallel adaptation of the
Complete topology, called Random, that has been shown to approximate the
behavior of Complete with far less
communication~\citep{mcnabb-2009-large-particle-swarms}.  In the Random
topology, each particle randomly picks two other particles to share information
with at each iteration, along with itself.  Thus in both the Ring and the
Random topologies, all particles have three neighbors.

The ideal topology and swarm size for PSO depend on the objective function.
Researchers have devised various benchmark functions and have found that the
ideal topology for one function may perform very poorly for another function.
The No Free Lunch Theorems for Optimization show that this is true in
general---if an algorithm performs well on average for one class of functions
then it must do poorly on average for other
problems~\citep{wolpert-1997-nfl-for-optimization}.

An attempt to standardize PSO found that although a Complete swarm of 50
particles converged to the global optimum more quickly for many benchmark
functions than the same swarm size with a Ring topology, it was also more
likely to permaturely converge to local optima for other functions.  The study
found no significant improvement for any other swarm size between 20 and 100
and concluded with a recommendation to use a swarm of 50 particles with a Ring
topology as a starting point.  The authors acknowledged that choosing the ideal
topology requires thorough experimentation for the particular
problem~\citep{bratton-2007-defining-a-standard-for-pso}.  Other authors have
explained that a large swarm with a sparse topology propogates information
slowly~\citep{montes-de-oca-2009-frankensteins-pso}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
% 1 to 2 pages

There have been several parallel implementations of PSO presented in the
literature.  These implementations vary along two axes---what computation is
performed and how it is done.  How the computation is performed involves both
architectural decisions, such as a master-slave versus a fully distributed
architecture, and decisions about synchronicity.  What computation is performed
involves decisions about how to scale the PSO algorithm for parallel
implementations, such as the ratio of particles to processors or the topology
to use.

\subsection{Synchronous vs. Asynchronous PSO}

Synchronous parallel implementations of PSO reproduce the standard serial
algorithm exactly.  This approach was first described analytically by
\citet{belal-2004-parallel-models-for-pso} and first implemented by
\citet{schutte-2004-parallel-global-optimization-with-pso}.  In a typical
master-slave algorithm, the master assigns tasks to slave processors, and in
parallel PSO, each task consists primarily of a function evaluation.  Updating
the particle's position and value may also be included in the
task~\citep{belal-2004-parallel-models-for-pso}, or this work may be performed
in serial by the
master~\citep{schutte-2004-parallel-global-optimization-with-pso}.  Before
proceeding to the next iteration, particles communicate, and each particle
updates its neighborhood best.  Whether this communication step happens
sequentially on the master or in parallel, each particle must receive
communication from its neighbors before proceeding.  The benefits of the
synchronous PSO include its simplicity, repeatability, and comparability with
standard PSO, which may be essential in research applications.

Asynchronous parallel
PSO~\citep{venter-2005-parallel-pso-asynchronous-evaluations,
koh-2006-parallel-asynchronous-pso} is a modification to the standard algorithm
which removes the synchronization point at the end of each iteration.  Instead,
particles iterate independently and communicate asynchronously.  In a typical
master-slave implementation of asynchronous parallel PSO, the master updates
each particle's personal best, neighborhood best, velocity, and position
immediately after receiving the function value from the slave processor.  Since
this update occurs while other particles are still being evaluated, it may use
information from the previous iteration for some
neighbors.\footnote{Asynchronous parallel PSO has been compared to the
``asynchronous updates'' variant of serial
PSO~\citep{koh-2006-parallel-asynchronous-pso}.  However, serial PSO with
asynchronous updates differs from standard PSO in that particles use newer
information, but asynchronous parallel PSO differs from standard PSO in that
particles use older information.} In a partially asynchronous implementation,
particles might wait for some but not all neighbors to complete before
proceeding~%
\citep{scriven-2008-asynchronous-pso-in-unreliable-distributed-environments}.
In some master-slave implementations, particles never get more than one
iteration ahead of
others~\citep{venter-2005-parallel-pso-asynchronous-evaluations,
koh-2006-parallel-asynchronous-pso}.  However, in a fully distributed
implementation, particles might never wait for information, and one particle
could complete many more iterations than another
particle~\citep{scriven-2008-distributed-pso-using-peer-to-peer}.  The main
effect of asynchronous evaluation is that processors spend less time
idle---this trait is particularly valuable when processors are heterogeneous or
function evaluation times are
varied~\citep{venter-2005-parallel-pso-asynchronous-evaluations,
koh-2006-parallel-asynchronous-pso}.  Asynchronous parallel PSO behaves
differently than the standard algorithm and may even produce different results
between runs.  Most reports conclude that asynchronous communication produces
similar numerical results to the standard algorithm, but the question has not
yet been thoroughly
addressed~\citep{venter-2005-parallel-pso-asynchronous-evaluations,
koh-2006-parallel-asynchronous-pso}.

\subsection{Scaling PSO to many processors}

The contribution of this work deals not with the implementation details of
architecture and synchronicity, but with what should be done with the PSO
equations when many hundreds or thousands of processors are available.  The
main issues that have been addressed in this space are how many particles to
use for a particular number of processors and what communication topology
should be employed.

The number of particles per processor has typically been decided by how long it
takes to evaluate the function being optimized.  When the function takes longer
than a few seconds to evaluate, previous techniques have assigned the number of
particles in the swarm to be the number of processors available~%
\citep{jin-2005-pso-antenna-designs,mcnabb-2009-large-particle-swarms},
advocating using as many processors as possible to get the best performance.
When the function takes less time to evaluate than the TCP/IP stack used to
send interprocessor communication, parallel implementations assign several or
many particles to a single processor~\citep{chu-2006-intelligent-parallel-pso,
chang-2005-parallel-pso-with-communication-strategies}.  Often the processor
only sends information about the best particle it evaluated to other
processors~\citep{mcnabb-2009-large-particle-swarms}.

Another popular method is simply to run PSO independently on each of the
processors available, taking the best result when all of the runs complete.  It
should be noted that this is equivalent to the previously stated method of
assigning many particles to each processor, only with no communication between
processors instead of little communication.  Both of these methods can be
described as changes in the communication topology of the original PSO
algorithm~\citep{mcnabb-2009-large-particle-swarms}.

Thus previous work in parallelizing PSO, apart from implementation details, has
consisted entirely of increasing the swarm size and adapting the topology to be
better suited to parallel computation.

With regard to increasing the swarm size in PSO, some recent work has suggested
that increasing the swarm size through the course of the optimization process
provides better results than having a set swarm
size~\citep{hsieh-2009-efficient-population-utilization-for-pso,
montes-de-oca-2010-incremental-social-learning-pso}.  However, these results
are based on total number of function evaluations, which, when running in
parallel on expensive functions, is less important than total number of
iterations.  Other work focusing on parallelization has shown that when extra
processors are available they should be used, as performance increases with
swarm size when measuring in terms of number of
iterations~\citep{mcnabb-2009-large-particle-swarms,
jin-2005-pso-antenna-designs}.  If the swarm size were varied throughout the
course of the optimization process, some processors would be sitting idle at
most iterations.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Thesis Statement}
% 1 to 2 sentences

When many processors are available, a speculative approach to the
parallelization of PSO can yield dramatic improvements in the performance of
the algorithm on expensive functions compared to previous parallelization
techniques.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Project Description}
% 2 to 5 pages

PSO can be trivially parallelized by assigning each particle's computation to
an individual processor.  But as we have seen in \figref{evals-sphere}, for
some functions, and for large numbers of processors, just adding particles
reaches a point of diminishing returns.  That is, adding processors does not
help the algorithm reach any given level of fitness appreciably faster.
Instead of adding particles we employ a speculative approach that allows us to
perform two iterations at a time.

\subsection{Refactoring the PSO Equations}

To perform two iterations at a time we must first refactor PSO such that the
determination of the value of the objective function is separate from the rest
of the computation.  For simplicity, this discussion will describe the case
where PSO is performing function minimization using the Ring topology.  In this
example, each particle has two neighbors, the ``right neighbor'' and ``left
neighbor,'' whose positions are represented as $\rightn$ and $\leftn$
respectively.  Though we will only describe the case of the Ring topology, this
method can easily be extended to arbitrary topologies.

The refactoring hinges on the idea that once the random coefficients
$\pURand_{t}$ and $\nURand_{t}$ are drawn, there are only a few possible new
positions, or updates, for $\nbest$ and $\pbest$.  For the Ring topology there
are 7 possible update cases, identified in Table~\ref{tab:evals}.  We label
each case with an identifier referring to the source of the update: a minus
sign ($-$) represents no update, $L$ represents an update to $\nbest$ coming
from the left neighbor, $R$ represents an update to $\nbest$ coming from the
right neighbor, and $S$ represents an update to either $\pbest$ or $\nbest$
coming from the particle itself.  As an example, $\casexn$ refers to the case
that the particle finds a new personal best, but neither it nor its neighbors
find a position that updated its neighborhood best.  In the equations that
follow, we refer to an unspecified update case as $\casegen$, and to the set of
cases collectively as $\caseset$.

\begin{table}
  \caption{All possible updates for a particle with two neighbors}
  \label{tab:evals}
  \centering
  \begin{tabular}{lcc}
	Identifier&Source of $\pbest$ update&Source of $\nbest$ update\\
	\hline
	\hline
	$\casepn$&No update&No update\\
	\hline
	$\casepl$&No update&Left Neighbor\\
	\hline
	$\casepr$&No update&Right Neighbor\\
	\hline
	$\casexn$&Self&No update\\
	\hline
	$\casexl$&Self&Left Neighbor\\
	\hline
	$\casexr$&Self&Right Neighbor\\
	\hline
	$\casexx$&Self&Self\\
	\hline
  \end{tabular}
\end{table}

In order to incorporate the determination of which case occurs into the
position and velocity update equations, we introduce an indicator function
$\indic_{t+1}^{\casegen}$ for each case $\casegen \in \caseset$.  When
$\casegen$ corresponds to the case actually taken by PSO,
$\indic_{t+1}^{\casegen}$ evaluates to 1; otherwise it evaluates to 0.  We can
then sum over all of the cases, and the indicator function will make all of the
terms drop to zero except for the case that actually occurs.  For example, the
indicator function for the specific case $\casexn$ (which, as is shown in
Table~\ref{tab:evals}, means that the particle's personal best was updated, but
its neighborhood best was not) can be written as follows:

\begin{align}
  \nonumber
	\indic_{t+1}^{\casexn} & (\ofunc ( \ppos_{t} ) ,\ofunc(\leftn_{t}),
	\ofunc(\rightn_{t}) ,\ofunc(\pbest_{t-1}) ,\ofunc(\nbest_{t-1}))= \\
  \label{eq:deficasexn}
	&\begin{cases}
	   1 & \text{if} \ \ofunc(\ppos_{t}) < \ofunc(\pbest_{t-1}) \\
	   &\quad \text{and} \quad \ofunc(\nbest_{t-1}) < \ofunc(\ppos_{t}) \\
	   &\quad \text{and} \quad \ofunc(\nbest_{t-1}) < \ofunc(\leftn_{t}) \\
	   &\quad \text{and} \quad \ofunc(\nbest_{t-1}) < \ofunc(\rightn_{t}) \\
	   0 & \text{otherwise}
	\end{cases}
\end{align}

For each case $\casegen \in \caseset$, there is also a corresponding
velocity update function $\specvel_{t+1}^{\casegen}$.  When the case is
known, the specific values of $\pbest_t$ and $\nbest_t$ may be substituted
directly into~\eqref{eq:velupdate}.  For example, in case $\casexn$,
$\pbest_{t}=\ppos_{t}$, as \pbest was updated by the particle's current
position, and $\nbest_{t}=\nbest_{t-1}$, as $\nbest$ was not updated at
iteration $t$:
\begin{align}
\nonumber
	\specvel_{t+1}^{\casexn} & (\pvel_t, \ppos_{t}, \leftn_{t}, \rightn_{t},
	\pbest_{t-1}, \nbest_{t-1}, \pURand_{t}, \nURand_{t}) \\
\label{eq:defvcasexn}
		&= \constriction \bigl[ \pvel_{t} +
			\pcoeff\pURand_{t}\otimes(\ppos_{t} - \ppos_{t})
			+ \ncoeff\nURand_{t}\otimes(\nbest_{t-1} -
			\ppos_{t}) \bigr]
\end{align}

In the same way we can create notation for the position update function by
substituting into~\eqref{eq:posupdate}.  For compactness, we will drop the
parameters to $\specvel_{t+1}^{\casegen}$ since they can be inferred from the
subscripts.
\begin{align}
\label{eq:defpcasegen}
	\specpos_{t+1}^{\casegen} & (\ppos_{t}, \pvel_{t}, \leftn_{t},
	\rightn_{t} ,\pbest_{t-1} ,\nbest_{t-1}, \pURand_{t}, \nURand_{t})
	= \ppos_{t} + \specvel_{t+1}^{\casegen}
\end{align}

With this notation we can re-write the original PSO velocity
equation~\eqref{eq:velupdate}, introducing our sum over cases with the
indicator functions.  Again, we represent the indicator functions and velocity
functions without the parameters for compactness.  The equation becomes:
\begin{align}
\nonumber
	\pvel_{t+1} &=
		\constriction \bigl[ \pvel_t
			+ \pcoeff\pURand_{t}\otimes(\pbest_{t} - \ppos_{t})
			+ \ncoeff\nURand_{t}\otimes(\nbest_{t} -
			\ppos_{t}) \bigr] \\
\nonumber
	&= \sum_{c \in \caseset} \indic_{t+1}^{c} \ \constriction \bigl[ \pvel_t
			+ \pcoeff\pURand_{t}\otimes(\pbest_{t} - \ppos_{t})
			+ \ncoeff\nURand_{t}\otimes(\nbest_{t} -
			\ppos_{t}) \bigr]  \\
\label{eq:vel2update}
	&= \sum_{c \in \caseset} \ \indic_{t+1}^{c} \ \specvel_{t+1}^{c} 
\end{align}

Similarly, the position update equation~\eqref{eq:posupdate} becomes:
\begin{align}
\label{eq:pos2update}
	\ppos_{t+1} &= \ppos_{t} + \pvel_{t+1}
	= \sum_{c \in \caseset} \ \indic_{t+1}^{c} \ \specpos_{t+1}^{c} 
\end{align}

The value of the objective function at $\ppos_{t+1}$ is given by:
\begin{align}
\label{eq:val2update}
	\ofunc (\ppos_{t+1}) = \sum_{c \in \caseset} \ \indic_{t+1}^{c}
	\ \ofunc(\specpos_{t+1}^{c})
\end{align}

Returning our attention to the computation of $\ppos_{t+1}$ in
\eqref{eq:pos2update} and writing it with the parameters which were omitted
above, we obtain:
\begin{align}
\nonumber
  \ppos_{t+1} = \sum_{c \in \caseset}
	&\indic_{t+1}^{c}(\ofunc ( \ppos_{t} ) ,\ofunc(\leftn_{t}),
	\ofunc(\rightn_{t}) ,\ofunc(\pbest_{t-1}) ,\ofunc(\nbest_{t-1})) \\
\label{eq:val2updatelong}
	& \specpos_{t+1}^{c}(\ppos_{t},\pvel_{t},\leftn_{t},\rightn_{t},
	\pbest_{t-1},\nbest_{t-1},\pURand_{t}, \nURand_{t})
\end{align}

In this form the important point to notice is that there are only $7$ values
(for this Ring topology) in the set $\{\specpos_{t+1}^{\casegen}: \casegen \in
\caseset\}$ and that none of them depend upon $f(\ppos_t)$ or any other
objective function evaluation at iteration $t$.  Note also that while there are
random numbers in the equation, they are assumed fixed once drawn for any
particular particle at a specific iteration.  Thus PSO has been refactored such
that the algorithm can begin computing all $7$ of the objective function
evaluations potentially needed in iteration $t+1$ \emph{before} $f(\ppos_t)$ is
computed.  Once the evaluation of $f(\ppos_{t})$ is completed for all particles
only one of the indicator functions $\indic_{t+1}^{\casegen}$ will be set to 1;
hence only one of the positions $\specpos_{t+1}^\casegen$ will be kept.

Although this speculative approach computes $\ofunc(\specpos_{t+1}^{\casegen})$
for all $\casegen \in \caseset$, even those for which $\indic_{t+1}^{\casegen}
= 0$, these extra computations will be ignored, and might just as well never
have been computed.  We call the set of computations
$\{\ofunc(\specpos_{t+1}^{c}) : \casegen \in \caseset\}$ ``speculative
children'' because only one of them will be needed.

\section{Validation}
% 1/2 to 2 pages

This project is expected to produce an implementation of speculative evaluation
in PSO, including several variations on the speculative evaluations performed.
The project will also show that speculative approaches to parallelization in
PSO result in improved performance over non-speculative approaches.

To show improved performance, we will test our methods against previous
parallelization methods on several benchmark functions.  While benchmark
functions themselves take fractions of a second to evaluate and thus have no
need of the kind of parallelization we explore in this project, they also have
no need of particle swarm optimization at all, as they can be solved
analytically.  Yet they are useful to us and to optimization researchers
generally because they stand as surrogates for the kinds of functions
practitioners are actually interested in, and they allow us to explore the
behavior of optimization algorithms on several different classes of functions
in an easy and standardized way.

We will measure our performance on these benchmark functions in terms of the
best value found at each iteration of the algorithms.  We will also compare the
total number of iterations required by each algorithm to reach some specified
value.  The project will be successful if a statistically significant decrease
in the number of iterations is observed.

\section{Thesis Schedule}
% 1/4 to 1/2 page

\begin{itemize}

\item Completed: Implement speculative evaluation in PSO and several
  improvements on it.

\item March 7, 2011: Finish running experiments and incorporate the results
  into the thesis.
  
\item March 15, 2011: Give final draft of thesis to advisor for review.

\item March 29, 2011: submit thesis to second committee member for review.

\item April 5, 2011: submit thesis to third committee member for review.

\item April 19, 2011: defend thesis.

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand\bibsection{\section{Annotated Bibliography}}
%\newcommand\bibpreamble{Material to be added between heading and entries.}
% 2 to 5 pages

\bibliography{../../../bib/pso/general/bib,%
../../../bib/pso/parallel/bib,%
../../../bib/pso/topology/bib,%
../../../bib/pso/fips/bib,%
../../../bib/aml/bib,%
../../../bib/parallel/bib,%
../../../bib/nfl/bib%
}


\end{document}
